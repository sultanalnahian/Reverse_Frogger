{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "from xlrd import open_workbook\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from build_vocab import Vocabulary\n",
    "from math import floor\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action to id map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions_map = dict()\n",
    "actions_map['Down'] = 0\n",
    "actions_map['Left'] = 1\n",
    "actions_map['Right'] = 2\n",
    "actions_map['Up'] = 3\n",
    "actions_map['Wait'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(current_image_dir, next_image_dir, good_ids, tr_indices):\n",
    "    current_images = os.listdir(current_image_dir)\n",
    "    current_images = sorted(current_images ,key = numericalSort)\n",
    "    \n",
    "    next_images = os.listdir(next_image_dir)\n",
    "    next_images = sorted(next_images ,key = numericalSort)\n",
    "    num_images = len(current_images)\n",
    "    \n",
    "    cur_training_images = []\n",
    "    next_training_images = []\n",
    "    cur_test_images = []\n",
    "    next_test_images = []\n",
    "    for i, file in enumerate(current_images):\n",
    "        if i in good_ids:\n",
    "            if good_ids[tr_indices[0]]<=i and i<=good_ids[tr_indices[1]]:\n",
    "                cur_training_images.append(file)\n",
    "                next_training_images.append(next_images[i])\n",
    "            else:\n",
    "                cur_test_images.append(file)\n",
    "                next_test_images.append(next_images[i])\n",
    "    \n",
    "    return cur_training_images, next_training_images, cur_test_images, next_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_file, vocab_path):\n",
    "    wb = open_workbook(data_file)\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    #vocab = vocab\n",
    "    #read the rationalizations from the excel file and create a list of training/testing rationalizations. \n",
    "    for sheet in wb.sheets():\n",
    "        number_of_rows = sheet.nrows\n",
    "        number_of_columns = sheet.ncols\n",
    "        rationalizations = []\n",
    "        items = []\n",
    "        rows = []\n",
    "        lengths = []\n",
    "        max_length = 0\n",
    "        \n",
    "        bad_worker_ids = ['A2CNSIECB9UP05','A23782O23HSPLA','A2F9ZBSR6AXXND','A3GI86L18Z71XY','AIXTI8PKSX1D2','A2QWHXMFQI18GQ','A3SB7QYI84HYJT',\n",
    "'A2Q2A7AB6MMFLI','A2P1KI42CJVNIA','A1IJXPKZTJV809','A2WZ0RZMKQ2WGJ','A3EKETMVGU2PM9','A1OCEC1TBE3CWA','AE1RYK54MH11G','A2ADEPVGNNXNPA',\n",
    "'A15QGLWS8CNJFU','A18O3DEA5Z4MJD','AAAL4RENVAPML','A3TZBZ92CQKQLG','ABO9F0JD9NN54','A8F6JFG0WSELT','ARN9ET3E608LJ','A2TCYNRAZWK8CC',\n",
    "'A32BK0E1IPDUAF','ANNV3E6CIVCW4','AXMQBHHU22TSP','AKATSYE8XLYNL','A355PGLV2ID2SX','A55CXM7QR7R0N','A111ZFNLXK1TCO']\n",
    "        \n",
    "        good_ids = []\n",
    "        good_rationalizations = []\n",
    "        actions = []\n",
    "        counter = Counter()\n",
    "        for row in range(1, number_of_rows):\n",
    "            values = []\n",
    "            worker_id = sheet.cell(row,0).value\n",
    "            if worker_id not in bad_worker_ids:\n",
    "                good_ids.append(row-1)\n",
    "                line = sheet.cell(row,4).value\n",
    "                tokens = nltk.tokenize.word_tokenize(line.lower())\n",
    "                # if tokens!=[]:\n",
    "                _action = sheet.cell(row,2).value\n",
    "                actions.append(actions_map[_action])\n",
    "                line = line.lower()\n",
    "                good_rationalizations.append(line)\n",
    "                line = re.sub('[^a-z\\ ]+', \" \", line)\n",
    "                words = line.split()\n",
    "                length = len(tokens)\n",
    "                lengths.append(length)\n",
    "                if length>max_length:\n",
    "                    max_length = length\n",
    "                for index,word in enumerate(tokens): \n",
    "                    tokens[index] = vocab.word2idx[word]\n",
    "                rationalizations.append(words)\n",
    "        rationalizations=[np.array(xi) for xi in rationalizations]\n",
    "\n",
    "    split = int(floor((90.0/100)*len(rationalizations)))\n",
    "    \n",
    "    # zzzz = nltk.tokenize.word_tokenize(' lksdfjoisd posidjf')\n",
    "    # print(zzzz)\n",
    "    # exit(0)\n",
    "    tr = slice(0,split)\n",
    "    tr_indices = [0,split-1]\n",
    "    te_indices = [split,len(rationalizations)-1]\n",
    "    te = slice(split,len(rationalizations))\n",
    "    training_rationalizations = good_rationalizations[tr]\n",
    "    testing_rationalizations = good_rationalizations[te]\n",
    "    training_actions = actions[tr]\n",
    "    testing_actions = actions[te]\n",
    "    # print(good_rationalizations)\n",
    "    # print(self.training_rationalizations)\n",
    "    # for r in self.training_rationalizations:\n",
    "    # \tif r==None:\n",
    "    # \t\tprint(\"first\")\n",
    "    # \t\texit(0)\n",
    "    # exit(0)\n",
    "    training_rationalizations_text = good_rationalizations[tr]\n",
    "    testing_rationalizations_text = good_rationalizations[te]\n",
    "    \n",
    "    \n",
    "    #current_image_dir = self.current_image_dir\n",
    "    #next_image_dir = self.next_image_dir\n",
    "    #output_dir = self.output_dir\n",
    "    #concatenated_images_dir = self.concatenated_images_dir\n",
    "    #subtracted_images_dir = self.subtracted_training_images_dir\n",
    "    #image_size = [self.image_size, self.image_size]\n",
    "    #image preprocessing\n",
    "    #crop and resize images. \n",
    "    \n",
    "    return good_ids, tr_indices, te_indices, training_rationalizations, testing_rationalizations, training_actions, testing_actions, vocab\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explanation_lstm_dim = 512\n",
    "batch_size = 8\n",
    "width = 320\n",
    "height = 320\n",
    "depth = 3\n",
    "max_words = 40\n",
    "n_words = 1000\n",
    "word_embed_dim = 512\n",
    "fc1_size = 4096\n",
    "image_embedding_size = 2048\n",
    "dim_hidden = 512\n",
    "comb_embedding_size = explanation_lstm_dim + dim_hidden\n",
    "num_output = 5\n",
    "drop_out_rate = 0.7\n",
    "max_rationalization_len = max_words\n",
    "learning_rate = 0.001\n",
    "max_epoch = 101\n",
    "dim_att = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert explanation texts to a matrix of word id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rationalization_matrix(rationalizations, vocab):\n",
    "    rationalization_matrix = []\n",
    "    sequence_lenght_arr = []\n",
    "    for sent in rationalizations:\n",
    "        sent = sent.replace(\"'\",\"\")\n",
    "        sent = sent.strip()\n",
    "        words = sent.lower().split(' ')\n",
    "        \n",
    "        ration_sent = np.zeros([ max_rationalization_len ], dtype=np.int32)\n",
    "        ration_sent[0] = 1\n",
    "        idx = 1\n",
    "    \n",
    "        for k, word in enumerate(words):\n",
    "            if idx == max_rationalization_len:\n",
    "                break\n",
    "            if word in vocab.word2idx:\n",
    "                ration_sent[idx] = vocab.word2idx[word]\n",
    "            else:\n",
    "                ration_sent[idx] = 3\n",
    "            idx +=1\n",
    "        \n",
    "        if idx < max_rationalization_len:\n",
    "            ration_sent[idx] = 2\n",
    "            idx += 1\n",
    "        rationalization_matrix.append(ration_sent)\n",
    "        sequence_lenght_arr.append(idx)\n",
    "\n",
    "    return rationalization_matrix, sequence_lenght_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(size):\n",
    "    return tf.contrib.rnn.BasicLSTMCell(size, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explanation_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell(explanation_lstm_dim) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_embeddings = tf.Variable(tf.constant(0.0, shape=[n_words, word_embed_dim]), trainable=True, name=\"wemb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_image_W = tf.Variable(tf.random_uniform([image_embedding_size, dim_hidden], -0.08, 0.08), name='embed_image_W')\n",
    "embed_image_b = tf.Variable(tf.random_uniform([dim_hidden], -0.08, 0.08), name='embed_image_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_scor_W = tf.Variable(tf.random_uniform([comb_embedding_size, num_output], -0.08, 0.08), name='embed_scor_W')\n",
    "embed_scor_b = tf.Variable(tf.random_uniform([num_output], -0.08, 0.08), name='embed_scor_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Convolutional Neural Network to encode the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_encoder(img_input):\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "        conv1 = tf.layers.conv2d(img_input, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.conv2d(conv1, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "        print(\"conv1: \",conv1)\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.conv2d(conv2, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "        print(\"conv2: \",conv2)\n",
    "    with tf.name_scope(\"conv3\"):\n",
    "        conv3 = tf.layers.conv2d(conv2, 128, 3, activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.conv2d(conv3, 128, 3, activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
    "        print(\"conv3: \",conv3)\n",
    "    with tf.name_scope(\"conv4\"):\n",
    "        conv4 = tf.layers.conv2d(conv3, 128, 3, activation=tf.nn.relu)\n",
    "        conv4 = tf.layers.max_pooling2d(conv4, 2, 2)\n",
    "        print(\"conv4: \",conv4)\n",
    "    with tf.name_scope(\"conv5\"):\n",
    "        conv5 = tf.layers.conv2d(conv4, 256, 3, activation=tf.nn.relu)\n",
    "        conv5 = tf.layers.max_pooling2d(conv5, 2, 2)\n",
    "        print(\"conv5: \",conv5)\n",
    "    with tf.name_scope(\"flatten\"):\n",
    "        flattened = tf.contrib.layers.flatten(conv5)\n",
    "        print(\"flattened: \", flattened)\n",
    "        \n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.layers.dense(flattened, fc1_size) \n",
    "    with tf.name_scope(\"fc\"):\n",
    "        fc = tf.layers.dense(fc1, image_embedding_size)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_w1 = tf.layers.Dense(512)\n",
    "attn_W2 = tf.layers.Dense(512)\n",
    "attn_V = tf.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention(exp_out, exp_hidden, image_emb):\n",
    "    hidden_with_time_axis = tf.expand_dims(exp_hidden, 1)\n",
    "    att1 = attn_w1(exp_out)\n",
    "    att2 = attn_W2(hidden_with_time_axis)\n",
    "    score = attn_V(tf.nn.tanh(att1 + att2))\n",
    "    #print(\"score: \", score)\n",
    "    attention_weights = tf.nn.softmax(score)\n",
    "    #print(\"attention_weights\",attention_weights)\n",
    "    context_vector = attention_weights * exp_out\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    #print(\"context_vector\", context_vector)\n",
    "    comb_emb = tf.concat([context_vector, image_emb], axis=-1)\n",
    "    #print(\"comb_emb\", comb_emb)\n",
    "    return attention_weights, comb_emb\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the architecture to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    image = tf.placeholder(tf.float32, [batch_size, width, height, depth])\n",
    "    explanation = tf.placeholder(tf.int32, [batch_size, max_words])\n",
    "    explanation_sequence_length = tf.placeholder(tf.int32, [batch_size])\n",
    "    action = tf.placeholder(tf.int32, [batch_size]) \n",
    "        \n",
    "    state = explanation_lstm.zero_state(batch_size, tf.float32)\n",
    "    loss = 0.0\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        text_embedding = tf.nn.embedding_lookup(W_embeddings, explanation)\n",
    "        \n",
    "        with tf.variable_scope('explanation_context'):\n",
    "            exp_outputs, state = tf.nn.dynamic_rnn(explanation_lstm, \n",
    "                                                   inputs = text_embedding, \n",
    "                                                   sequence_length= explanation_sequence_length,\n",
    "                                                   initial_state = state,\n",
    "                                                   dtype=tf.float32)\n",
    "        \n",
    "        exp_embedding = tf.reshape(tf.transpose(state, [2, 1, 0, 3]), [batch_size, -1])\n",
    "        \n",
    "        image_emb = image_encoder(image)\n",
    "        \n",
    "        image_emb = tf.nn.xw_plus_b(image_emb, embed_image_W, embed_image_b)\n",
    "        image_emb = tf.nn.relu(image_emb)\n",
    "        \n",
    "        #attention models\n",
    "        with tf.variable_scope(\"att1\"):\n",
    "            prob_att1, comb_emb = attention(exp_outputs, exp_embedding, image_emb)\n",
    "\n",
    "        comb_emb = tf.nn.dropout(comb_emb, 1 - drop_out_rate)\n",
    "        \n",
    "        scores_emb = tf.nn.xw_plus_b(comb_emb, embed_scor_W, embed_scor_b) \n",
    "        \n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=action, logits=scores_emb)\n",
    "        \n",
    "        _action = tf.reshape(action, [batch_size, -1])\n",
    "        onehot_action = tf.one_hot(_action, depth = num_output)\n",
    "        onehot_action = tf.reshape(onehot_action, [batch_size, -1])\n",
    "        \n",
    "        prediction = tf.nn.softmax(scores_emb)\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(onehot_action, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        return loss, accuracy, image, explanation, explanation_sequence_length, action, prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate the architecture to use during test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    image = tf.placeholder(tf.float32, [batch_size, width, height, depth])\n",
    "    explanation = tf.placeholder(tf.int32, [batch_size, max_words])\n",
    "    explanation_sequence_length = tf.placeholder(tf.int32, [batch_size])\n",
    "    action = tf.placeholder(tf.int32, [batch_size]) \n",
    "        \n",
    "    state = explanation_lstm.zero_state(batch_size, tf.float32)\n",
    "    loss = 0.0\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        text_embedding = tf.nn.embedding_lookup(W_embeddings, explanation)\n",
    "        \n",
    "        with tf.variable_scope('explanation_context'):\n",
    "            exp_outputs, state = tf.nn.dynamic_rnn(explanation_lstm, \n",
    "                                                   inputs = text_embedding, \n",
    "                                                   sequence_length= explanation_sequence_length,\n",
    "                                                   initial_state = state,\n",
    "                                                   dtype=tf.float32)\n",
    "        \n",
    "        exp_embedding = tf.reshape(tf.transpose(state, [2, 1, 0, 3]), [batch_size, -1])\n",
    "        \n",
    "        image_emb = image_encoder(image)\n",
    "        \n",
    "        image_emb = tf.nn.xw_plus_b(image_emb, embed_image_W, embed_image_b)\n",
    "        image_emb = tf.nn.relu(image_emb)\n",
    "        \n",
    "        with tf.variable_scope(\"att1\"):\n",
    "            prob_att1, comb_emb = attention(exp_outputs, exp_embedding, image_emb)\n",
    "\n",
    "        \n",
    "        scores_emb = tf.nn.xw_plus_b(comb_emb, embed_scor_W, embed_scor_b) \n",
    "        \n",
    "        _action = tf.reshape(action, [batch_size, -1])\n",
    "        onehot_action = tf.one_hot(_action, depth = num_output)\n",
    "        onehot_action = tf.reshape(onehot_action, [batch_size, -1])\n",
    "        \n",
    "        prediction = tf.nn.softmax(scores_emb)\n",
    "        result_action = tf.argmax(prediction, 1)\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(onehot_action, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        return accuracy, image, explanation, explanation_sequence_length, action, prediction, result_action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = './models_attention/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(cur_image_dir, next_image_dir):\n",
    "    \n",
    "    good_ids, training_indices, testing_indices, training_rationalizations, testing_rationalizations, trn_act, tst_act, vocab = load_data(\"Turk_Master_File.xlsx\", 'data/vocab_frogger.pkl')\n",
    "    cur_training_images, next_training_images, cur_test_images, next_test_images = load_images(current_image_dir, next_image_dir, good_ids, training_indices)\n",
    "\n",
    "    rationalization_matrix, ration_sqn_len = create_rationalization_matrix(training_rationalizations, vocab)\n",
    "    num_train = len(training_rationalizations)\n",
    "    rationalization_matrix = np.array(rationalization_matrix)\n",
    "    ration_sqn_len = np.array(ration_sqn_len)\n",
    "    cur_training_images = np.array(cur_training_images)\n",
    "    trn_act = np.array(trn_act)\n",
    "    tf_loss, tf_acc, tf_image, tf_explanation, tf_explanation_sequence_length, tf_action, tf_pred = build_model()\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    for epoch in range(0, max_epoch):\n",
    "        rationalization_matrix, ration_sqn_len, cur_training_images, trn_act = shuffle(\n",
    "            rationalization_matrix, ration_sqn_len, cur_training_images, trn_act)\n",
    "\n",
    "        #print(np.any(np.isnan(trn_act)))\n",
    "        tStart = time.time()\n",
    "        niter = 0\n",
    "        sum_loss = 0\n",
    "        sum_accuracy = 0\n",
    "        for current_batch_start_idx in range(0,num_train,batch_size):\n",
    "            if current_batch_start_idx + batch_size < num_train:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,current_batch_start_idx+batch_size)\n",
    "            else:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,num_train)\n",
    "\n",
    "\n",
    "            current_ration_text = rationalization_matrix[current_batch_file_idx,:]\n",
    "            current_sqn_len = ration_sqn_len[current_batch_file_idx]\n",
    "            current_img_list = cur_training_images[current_batch_file_idx]\n",
    "            current_actions = trn_act[current_batch_file_idx]\n",
    "            current_imgs_data = []\n",
    "            for img in current_img_list:\n",
    "                img_path = os.path.join(cur_image_dir, img)\n",
    "                img_arr = cv2.imread(img_path)\n",
    "                resized_img = cv2.resize(img_arr, (320,320))\n",
    "                current_imgs_data.append(resized_img)\n",
    "\n",
    "            current_imgs_data = np.array(current_imgs_data)\n",
    "            \n",
    "            \n",
    "            if len(current_ration_text) == batch_size:\n",
    "                _, loss, accuracy, prediction = sess.run([train_op, tf_loss, tf_acc, tf_pred],\n",
    "                    feed_dict={\n",
    "                        tf_image: current_imgs_data,\n",
    "                        tf_explanation: current_ration_text,\n",
    "                        tf_explanation_sequence_length: current_sqn_len,\n",
    "                        tf_action: current_actions})\n",
    "                niter +=1\n",
    "                sum_loss += loss\n",
    "                sum_accuracy += accuracy\n",
    "                \n",
    "        \n",
    "        avg_loss = sum_loss / niter\n",
    "        avg_acc = sum_accuracy/ niter\n",
    "        print(\"epoch: \", epoch, \" loss: \", avg_loss, \" accuracy: \", avg_acc, \" time: \", time.time() - tStart)\n",
    "        f_acc= open(\"train_acc_attention.txt\",\"a+\")\n",
    "        f_acc.write(\"epoch: \"+ str(epoch) + \" \"+\"Accuracy is: \" + str(avg_acc)+ \"%\\n\")\n",
    "        f_acc.close()\n",
    "        loss_arr.append(avg_loss)\n",
    "        acc_arr.append(avg_acc)\n",
    "        \n",
    "        if np.mod(epoch, 10) == 0:\n",
    "            print (\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "            saver.save(sess, os.path.join(model_path, 'frogger_model_attention'), global_step=epoch)\n",
    "        \n",
    "    return loss_arr, acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  Tensor(\"encoder/conv1/max_pooling2d/MaxPool:0\", shape=(8, 158, 158, 32), dtype=float32)\n",
      "conv2:  Tensor(\"encoder/conv2/max_pooling2d/MaxPool:0\", shape=(8, 77, 77, 64), dtype=float32)\n",
      "conv3:  Tensor(\"encoder/conv3/max_pooling2d/MaxPool:0\", shape=(8, 36, 36, 128), dtype=float32)\n",
      "conv4:  Tensor(\"encoder/conv4/max_pooling2d/MaxPool:0\", shape=(8, 17, 17, 128), dtype=float32)\n",
      "conv5:  Tensor(\"encoder/conv5/max_pooling2d/MaxPool:0\", shape=(8, 7, 7, 256), dtype=float32)\n",
      "flattened:  Tensor(\"encoder/flatten/Flatten/flatten/Reshape:0\", shape=(8, 12544), dtype=float32)\n",
      "score:  Tensor(\"encoder/att1/dense_3/BiasAdd:0\", shape=(8, 40, 1), dtype=float32)\n",
      "attention_weights Tensor(\"encoder/att1/Reshape_1:0\", shape=(8, 40, 1), dtype=float32)\n",
      "context_vector Tensor(\"encoder/att1/Sum:0\", shape=(8, 512), dtype=float32)\n",
      "comb_emb Tensor(\"encoder/att1/concat_1:0\", shape=(8, 1024), dtype=float32)\n",
      "epoch:  0  loss:  1.742277669483388  accuracy:  0.4519230769230769  time:  84.36119890213013\n",
      "epoch:  1  loss:  1.3041004986452633  accuracy:  0.46597633136094674  time:  56.4678475856781\n",
      "epoch:  2  loss:  1.2807504742808595  accuracy:  0.47115384615384615  time:  56.270567655563354\n",
      "epoch:  3  loss:  1.2567311694636147  accuracy:  0.47411242603550297  time:  56.58247208595276\n",
      "epoch:  4  loss:  1.2753668670823588  accuracy:  0.4718934911242604  time:  56.38127636909485\n",
      "epoch:  5  loss:  1.2579849408223078  accuracy:  0.47485207100591714  time:  56.50722599029541\n",
      "epoch:  6  loss:  1.2406005735933427  accuracy:  0.48372781065088755  time:  56.48452544212341\n",
      "epoch:  7  loss:  1.2235981620980438  accuracy:  0.4940828402366864  time:  56.53335165977478\n",
      "epoch:  8  loss:  1.2254444075053965  accuracy:  0.4940828402366864  time:  56.61880588531494\n",
      "epoch:  9  loss:  1.2011121804192222  accuracy:  0.511094674556213  time:  57.082157373428345\n",
      "epoch:  10  loss:  1.213678352226167  accuracy:  0.507396449704142  time:  56.27065825462341\n",
      "epoch:  11  loss:  1.1913159454362632  accuracy:  0.5051775147928994  time:  56.435022592544556\n",
      "epoch:  12  loss:  1.1898524958706467  accuracy:  0.5066568047337278  time:  56.42963409423828\n",
      "epoch:  13  loss:  1.1574729904973295  accuracy:  0.5244082840236687  time:  56.261252641677856\n",
      "epoch:  14  loss:  1.151464758187356  accuracy:  0.5547337278106509  time:  56.35861945152283\n",
      "epoch:  15  loss:  1.13706988642907  accuracy:  0.5473372781065089  time:  56.57285523414612\n",
      "epoch:  16  loss:  1.1219547002978578  accuracy:  0.5717455621301775  time:  57.585790157318115\n",
      "epoch:  17  loss:  1.0811159847050729  accuracy:  0.5769230769230769  time:  57.28298783302307\n",
      "epoch:  18  loss:  1.0834919189560344  accuracy:  0.5835798816568047  time:  56.68687129020691\n",
      "epoch:  19  loss:  1.0363970758646903  accuracy:  0.606508875739645  time:  58.014060974121094\n",
      "epoch:  20  loss:  1.0102247109074565  accuracy:  0.6316568047337278  time:  58.456480979919434\n",
      "epoch:  21  loss:  0.9796052361733815  accuracy:  0.636094674556213  time:  58.03992009162903\n",
      "epoch:  22  loss:  0.9480151812705768  accuracy:  0.6745562130177515  time:  58.707122564315796\n",
      "epoch:  23  loss:  0.8950372394725415  accuracy:  0.6908284023668639  time:  57.87649941444397\n",
      "epoch:  24  loss:  0.8582388301925546  accuracy:  0.7026627218934911  time:  57.71301198005676\n",
      "epoch:  25  loss:  0.8098937001454054  accuracy:  0.7115384615384616  time:  56.285518646240234\n",
      "epoch:  26  loss:  0.7898483272840285  accuracy:  0.7159763313609467  time:  56.75285530090332\n",
      "epoch:  27  loss:  0.7563566892633776  accuracy:  0.7307692307692307  time:  58.397164821624756\n",
      "epoch:  28  loss:  0.7230673073487874  accuracy:  0.7418639053254438  time:  58.66042423248291\n",
      "epoch:  29  loss:  0.6826855077369679  accuracy:  0.7514792899408284  time:  60.32202076911926\n",
      "epoch:  30  loss:  0.6605030995677914  accuracy:  0.7640532544378699  time:  58.65238904953003\n",
      "epoch:  31  loss:  0.6349857369294534  accuracy:  0.7840236686390533  time:  58.48511075973511\n",
      "epoch:  32  loss:  0.6116800855779083  accuracy:  0.7892011834319527  time:  58.57265019416809\n",
      "epoch:  33  loss:  0.6087236463274124  accuracy:  0.7877218934911243  time:  58.32127022743225\n",
      "epoch:  34  loss:  0.5869536664358963  accuracy:  0.7936390532544378  time:  59.07316780090332\n",
      "epoch:  35  loss:  0.5869005340972596  accuracy:  0.7921597633136095  time:  59.721121311187744\n",
      "epoch:  36  loss:  0.5574317054723846  accuracy:  0.8062130177514792  time:  57.9896719455719\n",
      "epoch:  37  loss:  0.533841267139954  accuracy:  0.8010355029585798  time:  60.208800077438354\n",
      "epoch:  38  loss:  0.5273057452055829  accuracy:  0.8187869822485208  time:  58.51600623130798\n",
      "epoch:  39  loss:  0.523163831555808  accuracy:  0.8128698224852071  time:  58.8361120223999\n",
      "epoch:  40  loss:  0.49204396165510605  accuracy:  0.8239644970414202  time:  57.40237808227539\n",
      "epoch:  41  loss:  0.5088583567130143  accuracy:  0.8143491124260355  time:  57.277684688568115\n",
      "epoch:  42  loss:  0.4923571982591815  accuracy:  0.8173076923076923  time:  56.93390488624573\n",
      "epoch:  43  loss:  0.4658943557968506  accuracy:  0.8461538461538461  time:  57.58217787742615\n",
      "epoch:  44  loss:  0.4686919763552014  accuracy:  0.8306213017751479  time:  56.99726724624634\n",
      "epoch:  45  loss:  0.4506939937795937  accuracy:  0.8380177514792899  time:  57.64065408706665\n",
      "epoch:  46  loss:  0.44325053722724406  accuracy:  0.849112426035503  time:  57.19825768470764\n",
      "epoch:  47  loss:  0.41520270665545433  accuracy:  0.860207100591716  time:  56.95006060600281\n",
      "epoch:  48  loss:  0.41431440854963114  accuracy:  0.8587278106508875  time:  58.40725898742676\n",
      "epoch:  49  loss:  0.41484644213283556  accuracy:  0.8646449704142012  time:  58.554057359695435\n",
      "epoch:  50  loss:  0.38903927223305024  accuracy:  0.8557692307692307  time:  58.70522499084473\n",
      "epoch:  51  loss:  0.3885808107636031  accuracy:  0.8720414201183432  time:  60.51372241973877\n",
      "epoch:  52  loss:  0.3773116872552231  accuracy:  0.8609467455621301  time:  58.776423931121826\n",
      "epoch:  53  loss:  0.34973384941426605  accuracy:  0.875  time:  56.76859378814697\n",
      "epoch:  54  loss:  0.35422474754279887  accuracy:  0.8853550295857988  time:  56.83387470245361\n",
      "epoch:  55  loss:  0.33081409899440745  accuracy:  0.8846153846153846  time:  56.675063133239746\n",
      "epoch:  56  loss:  0.3376219892025699  accuracy:  0.8809171597633136  time:  56.70666432380676\n",
      "epoch:  57  loss:  0.3151563214215301  accuracy:  0.8912721893491125  time:  56.57356858253479\n",
      "epoch:  58  loss:  0.3139472701559229  accuracy:  0.8890532544378699  time:  56.67193579673767\n",
      "epoch:  59  loss:  0.2819827465263344  accuracy:  0.9016272189349113  time:  57.30481195449829\n",
      "epoch:  60  loss:  0.2824386971997174  accuracy:  0.9038461538461539  time:  56.90560555458069\n",
      "epoch:  61  loss:  0.26517920972801434  accuracy:  0.908284023668639  time:  57.34458875656128\n",
      "epoch:  62  loss:  0.2611150080172797  accuracy:  0.9149408284023669  time:  56.64309096336365\n",
      "epoch:  63  loss:  0.26558106467568665  accuracy:  0.9001479289940828  time:  56.46090221405029\n",
      "epoch:  64  loss:  0.23832255278950965  accuracy:  0.9193786982248521  time:  56.59297728538513\n",
      "epoch:  65  loss:  0.23901495054231944  accuracy:  0.9208579881656804  time:  58.425936460494995\n",
      "epoch:  66  loss:  0.2095229159324215  accuracy:  0.9275147928994083  time:  57.43014359474182\n",
      "epoch:  67  loss:  0.22800682387011645  accuracy:  0.9275147928994083  time:  57.037906885147095\n",
      "epoch:  68  loss:  0.20192635416455523  accuracy:  0.9386094674556213  time:  57.253512144088745\n",
      "epoch:  69  loss:  0.19237393091471325  accuracy:  0.9341715976331361  time:  56.94160795211792\n",
      "epoch:  70  loss:  0.20699306099245754  accuracy:  0.9304733727810651  time:  56.653457164764404\n",
      "epoch:  71  loss:  0.18117247188750368  accuracy:  0.9423076923076923  time:  56.523566484451294\n",
      "epoch:  72  loss:  0.17176800239941425  accuracy:  0.9437869822485208  time:  56.42565417289734\n",
      "epoch:  73  loss:  0.1746153982477428  accuracy:  0.9386094674556213  time:  56.229755878448486\n",
      "epoch:  74  loss:  0.15224791289659867  accuracy:  0.9497041420118343  time:  56.20199370384216\n",
      "epoch:  75  loss:  0.148282316534025  accuracy:  0.9548816568047337  time:  56.339051961898804\n",
      "epoch:  76  loss:  0.14041968255397483  accuracy:  0.9556213017751479  time:  56.47939133644104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  77  loss:  0.14290106735886599  accuracy:  0.9519230769230769  time:  56.32093334197998\n",
      "epoch:  78  loss:  0.1305394832474681  accuracy:  0.9585798816568047  time:  56.6881959438324\n",
      "epoch:  79  loss:  0.1161467978756974  accuracy:  0.9674556213017751  time:  56.27603888511658\n",
      "epoch:  80  loss:  0.12187720127761938  accuracy:  0.9607988165680473  time:  56.31303954124451\n",
      "epoch:  81  loss:  0.11045497568109287  accuracy:  0.9659763313609467  time:  56.354652881622314\n",
      "epoch:  82  loss:  0.10934214188563003  accuracy:  0.9681952662721893  time:  55.96854567527771\n",
      "epoch:  83  loss:  0.10764131464474674  accuracy:  0.9704142011834319  time:  56.255192041397095\n",
      "epoch:  84  loss:  0.10202689967379966  accuracy:  0.9659763313609467  time:  56.28541159629822\n",
      "epoch:  85  loss:  0.08403111759059341  accuracy:  0.977810650887574  time:  56.50040006637573\n",
      "epoch:  86  loss:  0.07582220101292306  accuracy:  0.9822485207100592  time:  56.137359619140625\n",
      "epoch:  87  loss:  0.07190684600355732  accuracy:  0.981508875739645  time:  56.267335414886475\n",
      "epoch:  88  loss:  0.08065677106727642  accuracy:  0.9726331360946746  time:  56.282281160354614\n",
      "epoch:  89  loss:  0.0817736860097058  accuracy:  0.977810650887574  time:  56.52946925163269\n",
      "epoch:  90  loss:  0.07824301122124279  accuracy:  0.9800295857988166  time:  56.08174276351929\n",
      "epoch:  91  loss:  0.06886403572097415  accuracy:  0.981508875739645  time:  56.19123673439026\n",
      "epoch:  92  loss:  0.0586314256862357  accuracy:  0.9859467455621301  time:  56.29574370384216\n",
      "epoch:  93  loss:  0.06510632090923547  accuracy:  0.9822485207100592  time:  56.09891891479492\n",
      "epoch:  94  loss:  0.08568214406806993  accuracy:  0.9770710059171598  time:  56.19259452819824\n",
      "epoch:  95  loss:  0.0500520237421165  accuracy:  0.988905325443787  time:  56.214961767196655\n",
      "epoch:  96  loss:  0.05475822841154808  accuracy:  0.9881656804733728  time:  56.46472239494324\n",
      "epoch:  97  loss:  0.050443977119260575  accuracy:  0.9911242603550295  time:  56.26304221153259\n",
      "epoch:  98  loss:  0.039186988896952074  accuracy:  0.9918639053254438  time:  55.99322438240051\n",
      "epoch:  99  loss:  0.04672316077889285  accuracy:  0.985207100591716  time:  56.19483280181885\n",
      "epoch:  100  loss:  0.046108262075425385  accuracy:  0.9874260355029586  time:  56.21646976470947\n"
     ]
    }
   ],
   "source": [
    "current_image_dir = 'data/Frogger_Turk/Currrent_State'\n",
    "next_image_dir = 'data/Frogger_Turk/Next_State'\n",
    "loss_arr, acc_arr = train(current_image_dir, next_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAF3CAYAAACi+eJxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24cafd879b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(loss_arr)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(cur_image_dir, next_image_dir):\n",
    "    good_ids, training_indices, testing_indices, training_rationalizations, testing_rationalizations, trn_act, tst_act, vocab = load_data(\"Turk_Master_File.xlsx\", 'data/vocab_frogger.pkl')\n",
    "    cur_training_images, next_training_images, cur_test_images, next_test_images = load_images(current_image_dir, next_image_dir, good_ids, training_indices)\n",
    "    \n",
    "    rationalization_matrix, ration_sqn_len = create_rationalization_matrix(testing_rationalizations, vocab)\n",
    "    num_test = len(testing_rationalizations)\n",
    "    rationalization_matrix = np.array(rationalization_matrix)\n",
    "    ration_sqn_len = np.array(ration_sqn_len)\n",
    "    cur_training_images = np.array(cur_training_images)\n",
    "    trn_act = np.array(trn_act)\n",
    "    tf_accuracy, tf_image, tf_explanation, tf_explanation_sequence_length, tf_action, tf_prediction, tf_out_action = build_generator()\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    with tf.device('/cpu:0'):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, os.path.join(model_path, 'frogger_model_attention-100'))\n",
    "\n",
    "\n",
    "        \n",
    "    tStart = time.time()\n",
    "    \n",
    "    sum_accuracy = 0\n",
    "    niter = 0\n",
    "    for current_batch_start_idx in range(0,num_test,batch_size):\n",
    "        if current_batch_start_idx + batch_size < num_test:\n",
    "            current_batch_file_idx = range(current_batch_start_idx,current_batch_start_idx+batch_size)\n",
    "        else:\n",
    "            current_batch_file_idx = range(current_batch_start_idx,num_test)\n",
    "\n",
    "            #print(current_batch_file_idx)\n",
    "\n",
    "        current_ration_text = rationalization_matrix[current_batch_file_idx,:]\n",
    "        current_sqn_len = ration_sqn_len[current_batch_file_idx]\n",
    "        current_img_list = cur_training_images[current_batch_file_idx]\n",
    "        current_actions = trn_act[current_batch_file_idx]\n",
    "        current_imgs_data = []\n",
    "        for img in current_img_list:\n",
    "            img_path = os.path.join(cur_image_dir, img)\n",
    "            img_arr = cv2.imread(img_path)\n",
    "            resized_img = cv2.resize(img_arr, (320,320))\n",
    "            current_imgs_data.append(resized_img)\n",
    "\n",
    "        current_imgs_data = np.array(current_imgs_data)\n",
    "            \n",
    "            \n",
    "        if len(current_ration_text) == batch_size:\n",
    "            accuracy, prediction, out_action = sess.run([tf_accuracy, tf_prediction, tf_out_action],\n",
    "                                            feed_dict={\n",
    "                                                tf_image: current_imgs_data,\n",
    "                                                tf_explanation: current_ration_text,\n",
    "                                                tf_explanation_sequence_length: current_sqn_len,\n",
    "                                                tf_action: current_actions})\n",
    "            print(\"original actions: \", current_actions)\n",
    "            print(\"prediction: \", prediction)\n",
    "            print(\"output action: \", out_action)\n",
    "            niter +=1\n",
    "            sum_accuracy += accuracy\n",
    "                \n",
    "        \n",
    "    avg_acc = sum_accuracy/ niter\n",
    "    print(\"accuracy: \", avg_acc, \" time: \", time.time() - tStart)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  Tensor(\"encoder/conv1/max_pooling2d/MaxPool:0\", shape=(1, 158, 158, 32), dtype=float32)\n",
      "conv2:  Tensor(\"encoder/conv2/max_pooling2d/MaxPool:0\", shape=(1, 77, 77, 64), dtype=float32)\n",
      "conv3:  Tensor(\"encoder/conv3/max_pooling2d/MaxPool:0\", shape=(1, 36, 36, 128), dtype=float32)\n",
      "conv4:  Tensor(\"encoder/conv4/max_pooling2d/MaxPool:0\", shape=(1, 17, 17, 128), dtype=float32)\n",
      "conv5:  Tensor(\"encoder/conv5/max_pooling2d/MaxPool:0\", shape=(1, 7, 7, 256), dtype=float32)\n",
      "flattened:  Tensor(\"encoder/flatten/Flatten/flatten/Reshape:0\", shape=(1, 12544), dtype=float32)\n",
      "score:  Tensor(\"encoder/att1/dense_3/BiasAdd:0\", shape=(1, 40, 1), dtype=float32)\n",
      "attention_weights Tensor(\"encoder/att1/Reshape_1:0\", shape=(1, 40, 1), dtype=float32)\n",
      "context_vector Tensor(\"encoder/att1/Sum:0\", shape=(1, 512), dtype=float32)\n",
      "comb_emb Tensor(\"encoder/att1/concat_1:0\", shape=(1, 1024), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./models_attention/frogger_model_attention-100\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6137748e-06 9.4475690e-04 1.6530721e-02 9.8073822e-01 1.7847364e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.9165908e-07 1.1249683e-09 3.0322703e-08 9.9999785e-01 1.8507264e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.2476481e-05 1.2556430e-04 1.7029468e-02 9.8232818e-01 4.9430580e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4892814e-08 1.6793564e-12 6.5294884e-08 9.9999750e-01 2.3355906e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.1176736e-05 1.4503311e-03 6.1909477e-03 1.4079449e-05 9.9233353e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.7582503e-05 1.3262714e-01 1.0515686e-02 6.3324153e-01 2.2355805e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.9146886e-05 4.9617895e-01 4.0001014e-01 9.1175996e-02 1.2605780e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.05004957 0.42999363 0.18215957 0.3277771  0.01002013]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.5872202e-02 8.2829045e-03 9.2644823e-01 2.9212363e-02 1.8436996e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.8676430e-07 7.2989911e-07 5.2795567e-06 9.9998963e-01 3.8967787e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.3263873e-04 7.4793556e-04 6.7130841e-02 9.3022859e-01 1.7599533e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.4025565e-04 4.0729236e-04 4.0528215e-03 9.9396521e-01 1.4344068e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.1576893e-04 9.4532573e-01 7.0473854e-04 5.3397417e-02 4.5624634e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.8940047e-04 7.1044326e-01 4.4293436e-03 2.8431025e-01 3.2769222e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.0186282e-04 7.6352164e-02 2.8084472e-03 9.2054367e-01 1.9382870e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.1926594e-04 8.1572179e-03 3.0398924e-02 9.6027929e-01 9.4536570e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.1879965e-04 5.9163856e-04 1.5955602e-01 6.6878569e-01 1.7044778e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[9.8010888e-10 7.7460311e-07 9.2489731e-09 9.9999738e-01 1.8014168e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.8211491e-07 3.4307892e-04 1.5514289e-03 9.9785596e-01 2.4920370e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.3598297e-07 3.1262994e-04 1.2698553e-07 9.9958771e-01 9.9429097e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.0692968e-03 2.5336369e-04 1.1780421e-05 9.6083605e-01 3.6829472e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.01336516 0.00312933 0.15251565 0.00785435 0.82313544]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.4493923e-04 1.0269925e-09 4.2429130e-07 4.1278657e-01 5.8706808e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.6389598e-05 3.5705518e-03 1.7625990e-04 9.8506552e-01 1.1161317e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.01593769 0.02533125 0.05686137 0.15978496 0.7420848 ]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.00376101 0.03492704 0.06605553 0.80859596 0.08666052]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.3556206e-07 2.8495558e-07 1.8785153e-07 9.9999118e-01 8.2285223e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.1997089e-05 1.7305248e-04 6.9030793e-06 7.7496749e-01 2.2481053e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.1561413e-05 3.9364753e-04 2.8182831e-01 7.0930153e-01 8.4549701e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.0939324e-06 2.4549808e-11 4.5856190e-04 9.9933821e-01 2.0109996e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.3863580e-05 5.4852844e-06 9.9408275e-01 5.3079310e-03 5.7999016e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[9.3304808e-04 1.6275191e-05 9.8920470e-01 7.8755114e-03 1.9705100e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.2824202e-05 2.4975886e-06 3.3946272e-02 9.6600693e-01 2.1576347e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[9.6523550e-08 1.5195006e-09 1.5193673e-09 9.9999797e-01 1.9092565e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.60433000e-06 1.08003165e-04 5.94824678e-06 9.99597013e-01\n",
      "  2.83518137e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.3732962e-07 2.7191791e-06 1.5759650e-07 9.9933189e-01 6.6487334e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.0698985e-04 1.5687318e-04 3.2224688e-03 1.2066898e-01 8.7584466e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.6511642e-05 1.3827367e-05 1.6365650e-04 9.9944526e-01 3.2076568e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.2660031e-05 8.4927242e-06 2.7584818e-05 9.9990582e-01 5.4267812e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.3220498e-02 5.5365418e-03 6.4288732e-05 9.6842033e-01 1.2758387e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.07512846e-04 2.26828852e-03 3.20897177e-02 9.61837471e-01\n",
      "  3.69699532e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.5952438e-07 3.9758455e-05 5.6069263e-07 9.9991846e-01 4.1032963e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.4924925e-06 1.1619725e-05 1.8537463e-07 9.9881518e-01 1.1715463e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[6.9969508e-05 1.7011455e-04 2.7401730e-01 7.2017992e-01 5.5626831e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[4.7303706e-07 3.1151481e-03 9.9687165e-01 1.3880829e-07 1.2588538e-05]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.0944150e-05 1.3017656e-04 9.9921846e-01 3.7689324e-04 2.6350314e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.8539478e-04 1.6537652e-04 9.9552226e-01 2.4148098e-03 1.7121402e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.00257207 0.41368717 0.0166517  0.56542116 0.00166792]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00124499 0.01954317 0.04737643 0.9157121  0.01612327]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.6690265e-06 3.7883815e-01 2.2608163e-04 6.1913770e-01 1.7944050e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[4.2491724e-06 2.8360419e-02 9.7156674e-01 3.6095045e-08 6.8627494e-05]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.8249914e-04 2.5581708e-03 9.9142832e-01 3.1896182e-03 2.2412613e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.00117482 0.12825042 0.29844117 0.45681748 0.11531614]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.2419009e-04 7.7198502e-03 1.6155644e-01 8.2904649e-01 1.5531580e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.4384054e-05 8.8443512e-01 1.1392401e-01 5.9990177e-04 9.9652889e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.0197427e-05 8.1369624e-02 1.7508611e-03 9.1310084e-01 3.7484770e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.1366238e-04 1.6155160e-03 3.1240557e-05 9.8235172e-01 1.5887856e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[8.7441527e-05 8.9393714e-03 5.6745332e-05 9.9042106e-01 4.9544265e-04]]\n",
      "output action:  [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original actions:  [1]\n",
      "prediction:  [[5.645326e-06 8.133337e-03 8.162616e-05 6.895897e-01 3.021897e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.7825673e-05 9.0041239e-04 8.1005319e-06 2.4021374e-01 7.5882989e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.28216579e-05 2.00807070e-03 1.19408745e-04 9.95699525e-01\n",
      "  2.16021179e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.58956808e-04 5.45715809e-01 1.08150794e-04 2.70195037e-01\n",
      "  1.83622077e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.2776614e-04 2.0020621e-01 1.4304569e-02 3.6362424e-02 7.4899906e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.9600274e-06 7.2850651e-01 4.6901354e-03 6.4037502e-04 2.6616001e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.7237755e-06 9.8363459e-01 1.2536001e-04 7.1912850e-03 9.0469262e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.3471054e-05 1.7465208e-01 5.3822108e-02 7.6545060e-01 6.0617877e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00070663 0.03624859 0.0030611  0.5819505  0.3780332 ]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.5791118e-03 9.7444916e-01 9.9067642e-05 1.9430347e-02 3.4424267e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00443759 0.01522501 0.00235562 0.02276478 0.955217  ]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[6.2225113e-04 5.5623916e-03 4.7404642e-04 4.8688337e-02 9.4465297e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [0]\n",
      "prediction:  [[0.64496535 0.07398108 0.00173378 0.1916628  0.08765701]]\n",
      "output action:  [0]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.5352957e-07 7.6351583e-04 7.1669465e-06 9.9918813e-01 4.1070740e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.6430868e-05 2.8785276e-05 3.3859302e-05 9.9988651e-01 3.4498484e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.4756368e-04 7.9857701e-01 6.0058653e-04 5.7949575e-05 2.0061687e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.2149700e-02 9.8184586e-01 2.3507378e-03 1.1334856e-04 3.5403648e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[0.00139109 0.65286916 0.10084237 0.01297805 0.23191933]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[4.5864150e-04 4.6877293e-03 1.9735976e-01 4.8011664e-02 7.4948221e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.5005940e-06 2.0325170e-03 8.4205640e-05 9.9736112e-01 5.2062736e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.0046283e-07 9.3750560e-01 1.7434632e-04 7.4685246e-05 6.2245097e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.98198203e-08 8.40801306e-07 1.07912705e-07 9.99722779e-01\n",
      "  2.76221079e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.7554577e-05 8.3616160e-02 4.9683149e-04 9.1569865e-01 1.6075700e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.0964445e-04 1.7122219e-03 9.2646718e-01 6.9958068e-02 1.7528930e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.5720356e-05 7.7805867e-05 9.9474806e-01 5.0115995e-03 1.4675241e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.6521773e-05 5.1963643e-06 9.9674726e-01 2.9509007e-03 2.7010188e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[6.2666622e-05 5.9289732e-06 7.6634157e-01 2.3283710e-01 7.5269333e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[8.5889280e-07 1.1846879e-06 9.9997818e-01 7.3374081e-06 1.2360258e-05]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[9.0576223e-06 1.1064532e-07 2.3425794e-04 9.9967694e-01 7.9563499e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.5411657e-11 1.5165627e-23 2.8007219e-14 1.0000000e+00 1.0982472e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.1331112e-09 4.7139018e-08 7.0648438e-09 9.9999821e-01 1.8475987e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.0246359e-04 8.1847189e-03 1.4884413e-04 1.1850142e-01 8.7306249e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.9027198e-06 2.4247973e-05 9.6812091e-06 9.9927419e-01 6.8990659e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.7021698e-06 4.1659783e-05 1.9477618e-05 1.8213650e-02 9.8172152e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.72656154e-08 9.99990821e-01 9.09872142e-06 1.06848454e-10\n",
      "  1.46011317e-07]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.6778890e-08 9.9999857e-01 1.2723372e-06 2.6838872e-13 2.6926465e-08]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[2.2954845e-11 9.9999595e-01 1.3166381e-07 3.5500436e-15 3.9681472e-06]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.0227077e-05 8.9678558e-08 7.2725941e-03 9.8425180e-01 8.4552485e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6119751e-07 2.2305914e-10 1.2730303e-05 9.9998569e-01 1.4100792e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.70082117e-07 6.91739580e-13 3.19803526e-08 1.02854535e-01\n",
      "  8.97145271e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.5890922e-04 3.5195803e-06 1.3494155e-01 8.2655042e-01 3.8245544e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.6895893e-08 1.7468511e-07 1.0244862e-05 9.9998474e-01 4.8103052e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[6.0370778e-05 6.6331401e-04 1.0472610e-04 8.8930184e-01 1.0986977e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.1497794e-06 7.1394012e-08 2.6145760e-06 9.9570966e-01 4.2815707e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.5567087e-04 8.6007948e-04 9.8239857e-01 2.0121169e-04 1.6184554e-02]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.5042988e-05 1.1939614e-05 9.9974889e-01 8.9075793e-06 2.0524921e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.6525113e-04 2.2408833e-04 9.9618286e-01 7.2114292e-04 2.7065126e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.5133906e-07 4.1581944e-15 1.3341536e-04 9.9986422e-01 2.1812666e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.8078049e-08 8.4298241e-17 3.3858720e-09 9.9999821e-01 1.7603464e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6169910e-13 3.9710622e-27 1.0343596e-16 1.0000000e+00 1.2243107e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.6101662e-07 9.8579121e-01 1.4149323e-02 1.0158115e-08 5.9214035e-05]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.2149820e-09 9.9999702e-01 2.9527857e-06 1.7107569e-09 1.2469444e-08]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6427053e-04 9.2267891e-04 6.0030525e-05 9.9352938e-01 5.3236396e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[7.1588809e-05 2.1498824e-06 8.5752364e-03 9.9003369e-01 1.3173270e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4069015e-07 1.4082286e-07 3.4177428e-06 9.9999189e-01 4.1291282e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[8.5593041e-05 2.4501029e-05 3.6782400e-05 5.5587041e-01 4.4398272e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.5272150e-12 8.5192875e-10 4.7456284e-12 1.0000000e+00 3.5042083e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.5269517e-08 1.6360709e-05 1.4905148e-05 9.9995804e-01 1.0575967e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.1805259e-05 3.7130669e-02 1.2375226e-03 1.9894764e-03 9.5960051e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.2195319e-05 7.7467218e-02 8.7162998e-04 3.1005406e-01 6.1157489e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.3477129e-08 9.9977762e-01 1.9237392e-04 3.0442756e-11 3.0068504e-05]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.0004560e-09 9.9994969e-01 5.0042487e-05 7.7861502e-11 2.6320035e-07]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[6.4169189e-06 4.6056515e-04 2.2201673e-06 9.9383932e-01 5.6915721e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.2700509e-03 1.2684712e-04 2.7737685e-04 5.5308235e-01 4.4524330e-01]]\n",
      "output action:  [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original actions:  [1]\n",
      "prediction:  [[1.1273368e-06 1.0254549e-04 3.7428373e-07 7.6910484e-01 2.3079108e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.9715647e-05 2.1229625e-04 6.1621970e-05 9.9029070e-01 9.3856743e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.2121102e-02 8.8646094e-04 7.8342976e-03 9.7050560e-01 8.6524719e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00154356 0.00521481 0.00776558 0.00303736 0.98243874]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.9606744e-06 2.7095965e-17 1.1337019e-10 9.9982965e-01 1.6835614e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[5.8754313e-06 1.0375896e-06 1.9489042e-05 6.8514897e-03 9.9312204e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.6559658e-06 2.3550072e-12 2.0901613e-08 4.3379840e-02 9.5661551e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[8.3461809e-06 3.1624094e-07 1.2019424e-04 9.9920791e-01 6.6317868e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.0354430e-04 2.0848623e-01 3.4923595e-04 2.8408377e-04 7.9067689e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.7347186e-13 4.1226432e-26 4.6004027e-19 1.0000000e+00 9.9479864e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.60501293e-06 1.41048115e-08 1.96656586e-07 9.99458373e-01\n",
      "  5.39858302e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.1613544e-12 2.7505304e-25 8.3584642e-17 1.0000000e+00 9.7170778e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.3438931e-07 2.0317302e-05 4.2998462e-04 9.5456985e-09 9.9954933e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.4793644e-16 1.0000000e+00 2.7983383e-08 3.3632746e-27 4.6296083e-12]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.1875381e-23 1.0000000e+00 3.5094985e-13 3.7581135e-38 8.2262735e-17]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.1341249e-21 1.0000000e+00 1.6059049e-09 3.5416511e-34 1.1491442e-18]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[7.3823628e-11 9.9972123e-01 2.7873935e-04 7.7831485e-20 1.8723579e-08]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[7.1791992e-22 1.0000000e+00 8.4268106e-11 8.9313137e-38 3.3549514e-16]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.4576090e-08 2.8264661e-19 6.2808932e-11 8.1718022e-01 1.8281986e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.8592870e-16 2.6196511e-34 2.4773872e-21 1.0000000e+00 1.4225153e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00069942 0.38702536 0.02301905 0.01619384 0.5730623 ]]\n",
      "output action:  [4]\n",
      "original actions:  [2]\n",
      "prediction:  [[7.7943159e-06 1.5366503e-10 7.7377778e-04 9.9834454e-01 8.7389245e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[2.2690001e-06 1.5801541e-07 1.3391654e-05 8.2504112e-01 1.7494301e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.7112357e-15 1.3951202e-31 5.6818791e-22 1.0000000e+00 2.2057840e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[2.7691092e-27 1.0000000e+00 3.1995497e-14 0.0000000e+00 2.6351322e-22]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.1587770e-04 8.8061935e-01 1.9114910e-03 6.3490905e-02 5.3862426e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.2551660e-06 7.3056108e-01 2.5453556e-01 1.7753894e-04 1.4721473e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4412412e-15 4.8777077e-29 1.5322492e-19 1.0000000e+00 1.9020478e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[3.7420134e-05 3.1130970e-05 9.8779231e-01 2.8798211e-06 1.2136341e-02]]\n",
      "output action:  [2]\n",
      "accuracy:  0.609271523178808  time:  9.709046602249146\n"
     ]
    }
   ],
   "source": [
    "current_image_dir = 'data/Frogger_Turk/Currrent_State'\n",
    "next_image_dir = 'data/Frogger_Turk/Next_State'\n",
    "test(current_image_dir, next_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = [0.441, 0.529,0.609,0.769, 0.836, 0.893, 0.931, 0.952, 0.974, 0.988, 0.993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = [0.483, 0.503, 0.51, 0.444, 0.46, 0.44, 0.53, 0.543, 0.57, 0.583, 0.61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = [0,10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAF3CAYAAAC8MNLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1a8ef1b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epoch, training, label='training')\n",
    "plt.plot(epoch, testing, label='testing')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
