{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nahian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "from xlrd import open_workbook\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "from build_vocab import Vocabulary\n",
    "from math import floor\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action to id map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions_map = dict()\n",
    "actions_map['Down'] = 0\n",
    "actions_map['Left'] = 1\n",
    "actions_map['Right'] = 2\n",
    "actions_map['Up'] = 3\n",
    "actions_map['Wait'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(current_image_dir, next_image_dir, good_ids, tr_indices):\n",
    "    current_images = os.listdir(current_image_dir)\n",
    "    current_images = sorted(current_images ,key = numericalSort)\n",
    "    \n",
    "    next_images = os.listdir(next_image_dir)\n",
    "    next_images = sorted(next_images ,key = numericalSort)\n",
    "    num_images = len(current_images)\n",
    "    \n",
    "    cur_training_images = []\n",
    "    next_training_images = []\n",
    "    cur_test_images = []\n",
    "    next_test_images = []\n",
    "    for i, file in enumerate(current_images):\n",
    "        if i in good_ids:\n",
    "            if good_ids[tr_indices[0]]<=i and i<=good_ids[tr_indices[1]]:\n",
    "                cur_training_images.append(file)\n",
    "                next_training_images.append(next_images[i])\n",
    "            else:\n",
    "                cur_test_images.append(file)\n",
    "                next_test_images.append(next_images[i])\n",
    "    \n",
    "    return cur_training_images, next_training_images, cur_test_images, next_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_file, vocab_path):\n",
    "    wb = open_workbook(data_file)\n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    #vocab = vocab\n",
    "    #read the rationalizations from the excel file and create a list of training/testing rationalizations. \n",
    "    for sheet in wb.sheets():\n",
    "        number_of_rows = sheet.nrows\n",
    "        number_of_columns = sheet.ncols\n",
    "        rationalizations = []\n",
    "        items = []\n",
    "        rows = []\n",
    "        lengths = []\n",
    "        max_length = 0\n",
    "        \n",
    "        bad_worker_ids = ['A2CNSIECB9UP05','A23782O23HSPLA','A2F9ZBSR6AXXND','A3GI86L18Z71XY','AIXTI8PKSX1D2','A2QWHXMFQI18GQ','A3SB7QYI84HYJT',\n",
    "'A2Q2A7AB6MMFLI','A2P1KI42CJVNIA','A1IJXPKZTJV809','A2WZ0RZMKQ2WGJ','A3EKETMVGU2PM9','A1OCEC1TBE3CWA','AE1RYK54MH11G','A2ADEPVGNNXNPA',\n",
    "'A15QGLWS8CNJFU','A18O3DEA5Z4MJD','AAAL4RENVAPML','A3TZBZ92CQKQLG','ABO9F0JD9NN54','A8F6JFG0WSELT','ARN9ET3E608LJ','A2TCYNRAZWK8CC',\n",
    "'A32BK0E1IPDUAF','ANNV3E6CIVCW4','AXMQBHHU22TSP','AKATSYE8XLYNL','A355PGLV2ID2SX','A55CXM7QR7R0N','A111ZFNLXK1TCO']\n",
    "        \n",
    "        good_ids = []\n",
    "        good_rationalizations = []\n",
    "        actions = []\n",
    "        counter = Counter()\n",
    "        for row in range(1, number_of_rows):\n",
    "            values = []\n",
    "            worker_id = sheet.cell(row,0).value\n",
    "            if worker_id not in bad_worker_ids:\n",
    "                good_ids.append(row-1)\n",
    "                line = sheet.cell(row,4).value\n",
    "                tokens = nltk.tokenize.word_tokenize(line.lower())\n",
    "                # if tokens!=[]:\n",
    "                _action = sheet.cell(row,2).value\n",
    "                actions.append(actions_map[_action])\n",
    "                line = line.lower()\n",
    "                good_rationalizations.append(line)\n",
    "                line = re.sub('[^a-z\\ ]+', \" \", line)\n",
    "                words = line.split()\n",
    "                length = len(tokens)\n",
    "                lengths.append(length)\n",
    "                if length>max_length:\n",
    "                    max_length = length\n",
    "                for index,word in enumerate(tokens): \n",
    "                    tokens[index] = vocab.word2idx[word]\n",
    "                rationalizations.append(words)\n",
    "        rationalizations=[np.array(xi) for xi in rationalizations]\n",
    "\n",
    "    split = int(floor((90.0/100)*len(rationalizations)))\n",
    "    \n",
    "    # zzzz = nltk.tokenize.word_tokenize(' lksdfjoisd posidjf')\n",
    "    # print(zzzz)\n",
    "    # exit(0)\n",
    "    tr = slice(0,split)\n",
    "    tr_indices = [0,split-1]\n",
    "    te_indices = [split,len(rationalizations)-1]\n",
    "    te = slice(split,len(rationalizations))\n",
    "    training_rationalizations = good_rationalizations[tr]\n",
    "    testing_rationalizations = good_rationalizations[te]\n",
    "    training_actions = actions[tr]\n",
    "    testing_actions = actions[te]\n",
    "    # print(good_rationalizations)\n",
    "    # print(self.training_rationalizations)\n",
    "    # for r in self.training_rationalizations:\n",
    "    # \tif r==None:\n",
    "    # \t\tprint(\"first\")\n",
    "    # \t\texit(0)\n",
    "    # exit(0)\n",
    "    training_rationalizations_text = good_rationalizations[tr]\n",
    "    testing_rationalizations_text = good_rationalizations[te]\n",
    "    \n",
    "    \n",
    "    #current_image_dir = self.current_image_dir\n",
    "    #next_image_dir = self.next_image_dir\n",
    "    #output_dir = self.output_dir\n",
    "    #concatenated_images_dir = self.concatenated_images_dir\n",
    "    #subtracted_images_dir = self.subtracted_training_images_dir\n",
    "    #image_size = [self.image_size, self.image_size]\n",
    "    #image preprocessing\n",
    "    #crop and resize images. \n",
    "    \n",
    "    return good_ids, tr_indices, te_indices, training_rationalizations, testing_rationalizations, training_actions, testing_actions, vocab\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explanation_lstm_dim = 512\n",
    "batch_size = 1\n",
    "width = 320\n",
    "height = 320\n",
    "depth = 3\n",
    "max_words = 40\n",
    "n_words = 1000\n",
    "word_embed_dim = 512\n",
    "fc1_size = 4096\n",
    "image_embedding_size = 2048\n",
    "dim_hidden = 512\n",
    "comb_embedding_size = explanation_lstm_dim * 4 + dim_hidden\n",
    "num_output = 5\n",
    "drop_out_rate = 0.7\n",
    "max_rationalization_len = max_words\n",
    "learning_rate = 0.001\n",
    "max_epoch = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert explanation texts to a matrix of word id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rationalization_matrix(rationalizations, vocab):\n",
    "    rationalization_matrix = []\n",
    "    sequence_lenght_arr = []\n",
    "    for sent in rationalizations:\n",
    "        sent = sent.replace(\"'\",\"\")\n",
    "        sent = sent.strip()\n",
    "        words = sent.lower().split(' ')\n",
    "        \n",
    "        ration_sent = np.zeros([ max_rationalization_len ], dtype=np.int32)\n",
    "        ration_sent[0] = 1\n",
    "        idx = 1\n",
    "    \n",
    "        for k, word in enumerate(words):\n",
    "            if idx == max_rationalization_len:\n",
    "                break\n",
    "            if word in vocab.word2idx:\n",
    "                ration_sent[idx] = vocab.word2idx[word]\n",
    "            else:\n",
    "                ration_sent[idx] = 3\n",
    "            idx +=1\n",
    "        \n",
    "        if idx < max_rationalization_len:\n",
    "            ration_sent[idx] = 2\n",
    "            idx += 1\n",
    "        rationalization_matrix.append(ration_sent)\n",
    "        sequence_lenght_arr.append(idx)\n",
    "\n",
    "    return rationalization_matrix, sequence_lenght_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(size):\n",
    "    return tf.contrib.rnn.BasicLSTMCell(size, reuse=tf.AUTO_REUSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explanation_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell(explanation_lstm_dim) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_embeddings = tf.Variable(tf.constant(0.0, shape=[n_words, word_embed_dim]), trainable=True, name=\"wemb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_image_W = tf.Variable(tf.random_uniform([image_embedding_size, dim_hidden], -0.08, 0.08), name='embed_image_W')\n",
    "embed_image_b = tf.Variable(tf.random_uniform([dim_hidden], -0.08, 0.08), name='embed_image_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed_scor_W = tf.Variable(tf.random_uniform([comb_embedding_size, num_output], -0.08, 0.08), name='embed_scor_W')\n",
    "embed_scor_b = tf.Variable(tf.random_uniform([num_output], -0.08, 0.08), name='embed_scor_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Convolutional Neural Network to encode the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_encoder(img_input):\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "        conv1 = tf.layers.conv2d(img_input, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.conv2d(conv1, 32, 3, activation=tf.nn.relu)\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "        print(\"conv1: \",conv1)\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.conv2d(conv2, 64, 3, activation=tf.nn.relu)\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "        print(\"conv2: \",conv2)\n",
    "    with tf.name_scope(\"conv3\"):\n",
    "        conv3 = tf.layers.conv2d(conv2, 128, 3, activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.conv2d(conv3, 128, 3, activation=tf.nn.relu)\n",
    "        conv3 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
    "        print(\"conv3: \",conv3)\n",
    "    with tf.name_scope(\"conv4\"):\n",
    "        conv4 = tf.layers.conv2d(conv3, 128, 3, activation=tf.nn.relu)\n",
    "        conv4 = tf.layers.max_pooling2d(conv4, 2, 2)\n",
    "        print(\"conv4: \",conv4)\n",
    "    with tf.name_scope(\"conv5\"):\n",
    "        conv5 = tf.layers.conv2d(conv4, 256, 3, activation=tf.nn.relu)\n",
    "        conv5 = tf.layers.max_pooling2d(conv5, 2, 2)\n",
    "        print(\"conv5: \",conv5)\n",
    "    with tf.name_scope(\"flatten\"):\n",
    "        flattened = tf.contrib.layers.flatten(conv5)\n",
    "        print(\"flattened: \", flattened)\n",
    "        \n",
    "    with tf.name_scope(\"fc1\"):\n",
    "        fc1 = tf.layers.dense(flattened, fc1_size) \n",
    "    with tf.name_scope(\"fc\"):\n",
    "        fc = tf.layers.dense(fc1, image_embedding_size)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the architecture to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    image = tf.placeholder(tf.float32, [batch_size, width, height, depth])\n",
    "    explanation = tf.placeholder(tf.int32, [batch_size, max_words])\n",
    "    explanation_sequence_length = tf.placeholder(tf.int32, [batch_size])\n",
    "    action = tf.placeholder(tf.int32, [batch_size]) \n",
    "        \n",
    "    state = explanation_lstm.zero_state(batch_size, tf.float32)\n",
    "    loss = 0.0\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        text_embedding = tf.nn.embedding_lookup(W_embeddings, explanation)\n",
    "        \n",
    "        with tf.variable_scope('explanation_context'):\n",
    "            exp_outputs, state = tf.nn.dynamic_rnn(explanation_lstm, \n",
    "                                                   inputs = text_embedding, \n",
    "                                                   sequence_length= explanation_sequence_length,\n",
    "                                                   initial_state = state,\n",
    "                                                   dtype=tf.float32)\n",
    "        \n",
    "        exp_embedding = tf.reshape(tf.transpose(state, [2, 1, 0, 3]), [batch_size, -1])\n",
    "        \n",
    "        image_emb = image_encoder(image)\n",
    "        \n",
    "        image_emb = tf.nn.xw_plus_b(image_emb, embed_image_W, embed_image_b)\n",
    "        image_emb = tf.nn.relu(image_emb)\n",
    "        \n",
    "        comb_emb = tf.concat([image_emb, exp_embedding], 1)\n",
    "        comb_emb = tf.nn.dropout(comb_emb, 1 - drop_out_rate)\n",
    "        \n",
    "        scores_emb = tf.nn.xw_plus_b(comb_emb, embed_scor_W, embed_scor_b) \n",
    "        \n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=action, logits=scores_emb)\n",
    "        \n",
    "        _action = tf.reshape(action, [batch_size, -1])\n",
    "        onehot_action = tf.one_hot(_action, depth = num_output)\n",
    "        onehot_action = tf.reshape(onehot_action, [batch_size, -1])\n",
    "        \n",
    "        prediction = tf.nn.softmax(scores_emb)\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(onehot_action, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        return loss, accuracy, image, explanation, explanation_sequence_length, action, prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generate the architecture to use during test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    image = tf.placeholder(tf.float32, [batch_size, width, height, depth])\n",
    "    explanation = tf.placeholder(tf.int32, [batch_size, max_words])\n",
    "    explanation_sequence_length = tf.placeholder(tf.int32, [batch_size])\n",
    "    action = tf.placeholder(tf.int32, [batch_size]) \n",
    "        \n",
    "    state = explanation_lstm.zero_state(batch_size, tf.float32)\n",
    "    loss = 0.0\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        text_embedding = tf.nn.embedding_lookup(W_embeddings, explanation)\n",
    "        \n",
    "        with tf.variable_scope('explanation_context'):\n",
    "            exp_outputs, state = tf.nn.dynamic_rnn(explanation_lstm, \n",
    "                                                   inputs = text_embedding, \n",
    "                                                   sequence_length= explanation_sequence_length,\n",
    "                                                   initial_state = state,\n",
    "                                                   dtype=tf.float32)\n",
    "        \n",
    "        exp_embedding = tf.reshape(tf.transpose(state, [2, 1, 0, 3]), [batch_size, -1])\n",
    "        \n",
    "        image_emb = image_encoder(image)\n",
    "        \n",
    "        image_emb = tf.nn.xw_plus_b(image_emb, embed_image_W, embed_image_b)\n",
    "        image_emb = tf.nn.relu(image_emb)\n",
    "        \n",
    "\n",
    "        comb_emb = tf.concat([image_emb, exp_embedding], 1)\n",
    "        #comb_emb = tf.nn.dropout(comb_emb, 1 - drop_out_rate)\n",
    "        \n",
    "        scores_emb = tf.nn.xw_plus_b(comb_emb, embed_scor_W, embed_scor_b) \n",
    "        \n",
    "        _action = tf.reshape(action, [batch_size, -1])\n",
    "        onehot_action = tf.one_hot(_action, depth = num_output)\n",
    "        onehot_action = tf.reshape(onehot_action, [batch_size, -1])\n",
    "        \n",
    "        prediction = tf.nn.softmax(scores_emb)\n",
    "        result_action = tf.argmax(prediction, 1)\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(onehot_action, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        return accuracy, image, explanation, explanation_sequence_length, action, prediction, result_action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = './models_batch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(cur_image_dir, next_image_dir):\n",
    "    \n",
    "    good_ids, training_indices, testing_indices, training_rationalizations, testing_rationalizations, trn_act, tst_act, vocab = load_data(\"Turk_Master_File.xlsx\", 'data/vocab_frogger.pkl')\n",
    "    cur_training_images, next_training_images, cur_test_images, next_test_images = load_images(current_image_dir, next_image_dir, good_ids, training_indices)\n",
    "    #print(\"training ration: \", len(training_rationalizations))\n",
    "    #print(\"current_training_images : \",len(cur_training_images))\n",
    "    #print(\"next_training_images : \", next_training_images)\n",
    "    rationalization_matrix, ration_sqn_len = create_rationalization_matrix(training_rationalizations, vocab)\n",
    "    num_train = len(training_rationalizations)\n",
    "    rationalization_matrix = np.array(rationalization_matrix)\n",
    "    ration_sqn_len = np.array(ration_sqn_len)\n",
    "    cur_training_images = np.array(cur_training_images)\n",
    "    trn_act = np.array(trn_act)\n",
    "    tf_loss, tf_acc, tf_image, tf_explanation, tf_explanation_sequence_length, tf_action, tf_pred = build_model()\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    for epoch in range(0, max_epoch):\n",
    "        rationalization_matrix, ration_sqn_len, cur_training_images, trn_act = shuffle(\n",
    "            rationalization_matrix, ration_sqn_len, cur_training_images, trn_act)\n",
    "\n",
    "        #print(np.any(np.isnan(trn_act)))\n",
    "        tStart = time.time()\n",
    "        niter = 0\n",
    "        sum_loss = 0\n",
    "        sum_accuracy = 0\n",
    "        for current_batch_start_idx in range(0,num_train,batch_size):\n",
    "            if current_batch_start_idx + batch_size < num_train:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,current_batch_start_idx+batch_size)\n",
    "            else:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,num_train)\n",
    "\n",
    "            #print(current_batch_file_idx)\n",
    "\n",
    "            current_ration_text = rationalization_matrix[current_batch_file_idx,:]\n",
    "            current_sqn_len = ration_sqn_len[current_batch_file_idx]\n",
    "            current_img_list = cur_training_images[current_batch_file_idx]\n",
    "            current_actions = trn_act[current_batch_file_idx]\n",
    "            current_imgs_data = []\n",
    "            for img in current_img_list:\n",
    "                img_path = os.path.join(cur_image_dir, img)\n",
    "                img_arr = cv2.imread(img_path)\n",
    "                resized_img = cv2.resize(img_arr, (320,320))\n",
    "                current_imgs_data.append(resized_img)\n",
    "\n",
    "            current_imgs_data = np.array(current_imgs_data)\n",
    "            \n",
    "            \n",
    "            if len(current_ration_text) == batch_size:\n",
    "                _, loss, accuracy, prediction = sess.run([train_op, tf_loss, tf_acc, tf_pred],\n",
    "                    feed_dict={\n",
    "                        tf_image: current_imgs_data,\n",
    "                        tf_explanation: current_ration_text,\n",
    "                        tf_explanation_sequence_length: current_sqn_len,\n",
    "                        tf_action: current_actions})\n",
    "                niter +=1\n",
    "                sum_loss += loss\n",
    "                sum_accuracy += accuracy\n",
    "                #print(\"iter: \", niter, \" loss: \", loss, \" accuracy: \", accuracy)\n",
    "                #print(\"current_actions\", current_actions)\n",
    "                #print(\"prediction\", prediction)\n",
    "                \n",
    "        \n",
    "        avg_loss = sum_loss / niter\n",
    "        avg_acc = sum_accuracy/ niter\n",
    "        print(\"epoch: \", epoch, \" loss: \", avg_loss, \" accuracy: \", avg_acc, \" time: \", time.time() - tStart)\n",
    "        f_acc= open(\"train_acc.txt\",\"a+\")\n",
    "        f_acc.write(\"epoch: \"+ str(epoch) + \" \"+\"Accuracy is: \" + str(avg_acc)+ \"%\\n\")\n",
    "        f_acc.close()\n",
    "        \n",
    "        loss_arr.append(avg_loss)\n",
    "        acc_arr.append(avg_acc)\n",
    "        \n",
    "        if np.mod(epoch, 10) == 0:\n",
    "            print (\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "            saver.save(sess, os.path.join(model_path, 'frogger_model'), global_step=epoch)\n",
    "        \n",
    "    return loss_arr, acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  Tensor(\"encoder/conv1/max_pooling2d/MaxPool:0\", shape=(8, 158, 158, 32), dtype=float32)\n",
      "conv2:  Tensor(\"encoder/conv2/max_pooling2d/MaxPool:0\", shape=(8, 77, 77, 64), dtype=float32)\n",
      "conv3:  Tensor(\"encoder/conv3/max_pooling2d/MaxPool:0\", shape=(8, 36, 36, 128), dtype=float32)\n",
      "conv4:  Tensor(\"encoder/conv4/max_pooling2d/MaxPool:0\", shape=(8, 17, 17, 128), dtype=float32)\n",
      "conv5:  Tensor(\"encoder/conv5/max_pooling2d/MaxPool:0\", shape=(8, 7, 7, 256), dtype=float32)\n",
      "flattened:  Tensor(\"encoder/flatten/Flatten/flatten/Reshape:0\", shape=(8, 12544), dtype=float32)\n",
      "epoch:  0  loss:  2.082490588786334  accuracy:  0.4326923076923077  time:  57.28927946090698\n",
      "epoch:  1  loss:  1.289317589539748  accuracy:  0.4593195266272189  time:  55.203702211380005\n",
      "epoch:  2  loss:  1.2707746632000398  accuracy:  0.47115384615384615  time:  55.24795937538147\n",
      "epoch:  3  loss:  1.259851895140473  accuracy:  0.4911242603550296  time:  55.47174787521362\n",
      "epoch:  4  loss:  1.2500874893905143  accuracy:  0.4807692307692308  time:  54.974844217300415\n",
      "epoch:  5  loss:  1.2422672485458781  accuracy:  0.48372781065088755  time:  54.89231204986572\n",
      "epoch:  6  loss:  1.236526354530154  accuracy:  0.4918639053254438  time:  55.127779483795166\n",
      "epoch:  7  loss:  1.2268245823284578  accuracy:  0.5  time:  55.773661375045776\n",
      "epoch:  8  loss:  1.2148275914982225  accuracy:  0.4940828402366864  time:  55.26532196998596\n",
      "epoch:  9  loss:  1.218095794231934  accuracy:  0.4896449704142012  time:  55.15437841415405\n",
      "epoch:  10  loss:  1.2085064339214528  accuracy:  0.5081360946745562  time:  55.78476929664612\n",
      "epoch:  11  loss:  1.195413136976005  accuracy:  0.5066568047337278  time:  55.5496027469635\n",
      "epoch:  12  loss:  1.1734125995071683  accuracy:  0.518491124260355  time:  56.04485821723938\n",
      "epoch:  13  loss:  1.1666248908057015  accuracy:  0.5214497041420119  time:  55.17464828491211\n",
      "epoch:  14  loss:  1.161162440240736  accuracy:  0.5044378698224852  time:  55.22918224334717\n",
      "epoch:  15  loss:  1.1433115351129566  accuracy:  0.5325443786982249  time:  55.401764154434204\n",
      "epoch:  16  loss:  1.139049768447876  accuracy:  0.5288461538461539  time:  55.225677728652954\n",
      "epoch:  17  loss:  1.1221716721382367  accuracy:  0.5355029585798816  time:  55.18238544464111\n",
      "epoch:  18  loss:  1.1085434026972076  accuracy:  0.5495562130177515  time:  54.95377802848816\n",
      "epoch:  19  loss:  1.0968052136474813  accuracy:  0.5650887573964497  time:  55.13419246673584\n",
      "epoch:  20  loss:  1.0732265760207318  accuracy:  0.5717455621301775  time:  55.30420136451721\n",
      "epoch:  21  loss:  1.0458253868938199  accuracy:  0.5902366863905325  time:  55.29816007614136\n",
      "epoch:  22  loss:  1.0080857555541767  accuracy:  0.6146449704142012  time:  55.732908725738525\n",
      "epoch:  23  loss:  0.9503151721502903  accuracy:  0.6383136094674556  time:  55.77552366256714\n",
      "epoch:  24  loss:  0.9215797028950685  accuracy:  0.6531065088757396  time:  55.71052694320679\n",
      "epoch:  25  loss:  0.8826451721276052  accuracy:  0.6782544378698225  time:  57.110504388809204\n",
      "epoch:  26  loss:  0.8420919741575534  accuracy:  0.6797337278106509  time:  55.73214530944824\n",
      "epoch:  27  loss:  0.8016976935447321  accuracy:  0.6930473372781065  time:  55.83382058143616\n",
      "epoch:  28  loss:  0.7864994676508141  accuracy:  0.7130177514792899  time:  55.9825005531311\n",
      "epoch:  29  loss:  0.7490549948970242  accuracy:  0.7263313609467456  time:  55.05085897445679\n",
      "epoch:  30  loss:  0.7084865641928989  accuracy:  0.7300295857988166  time:  54.86648941040039\n",
      "epoch:  31  loss:  0.676961929664104  accuracy:  0.7366863905325444  time:  54.9487783908844\n",
      "epoch:  32  loss:  0.6788330336470576  accuracy:  0.738905325443787  time:  54.91682004928589\n",
      "epoch:  33  loss:  0.6551106648861303  accuracy:  0.7522189349112426  time:  55.32262349128723\n",
      "epoch:  34  loss:  0.6449639691844494  accuracy:  0.7522189349112426  time:  56.77819299697876\n",
      "epoch:  35  loss:  0.6140029815262591  accuracy:  0.7633136094674556  time:  57.21102452278137\n",
      "epoch:  36  loss:  0.5907446992467846  accuracy:  0.775887573964497  time:  59.22421741485596\n",
      "epoch:  37  loss:  0.584943791399517  accuracy:  0.7744082840236687  time:  59.53731346130371\n",
      "epoch:  38  loss:  0.5546803764734395  accuracy:  0.7847633136094675  time:  59.1092689037323\n",
      "epoch:  39  loss:  0.532403896898913  accuracy:  0.8002958579881657  time:  59.12717914581299\n",
      "epoch:  40  loss:  0.527533885863053  accuracy:  0.7958579881656804  time:  58.76094102859497\n",
      "epoch:  41  loss:  0.515006960716826  accuracy:  0.8076923076923077  time:  59.10329341888428\n",
      "epoch:  42  loss:  0.47231626911805225  accuracy:  0.8217455621301775  time:  59.38341021537781\n",
      "epoch:  43  loss:  0.49071253957392197  accuracy:  0.8128698224852071  time:  57.31864547729492\n",
      "epoch:  44  loss:  0.44115297156854494  accuracy:  0.8254437869822485  time:  56.9900176525116\n",
      "epoch:  45  loss:  0.45685612196488495  accuracy:  0.8143491124260355  time:  56.70678949356079\n",
      "epoch:  46  loss:  0.4404423677379034  accuracy:  0.8180473372781065  time:  56.68872570991516\n",
      "epoch:  47  loss:  0.40175615118805474  accuracy:  0.8409763313609467  time:  56.66609215736389\n",
      "epoch:  48  loss:  0.38959694614071816  accuracy:  0.8461538461538461  time:  56.70142078399658\n",
      "epoch:  49  loss:  0.3667989765244299  accuracy:  0.8513313609467456  time:  56.87014436721802\n",
      "epoch:  50  loss:  0.3834453600530441  accuracy:  0.8409763313609467  time:  57.10375142097473\n",
      "epoch:  51  loss:  0.3866762012772306  accuracy:  0.8424556213017751  time:  56.705350399017334\n",
      "epoch:  52  loss:  0.3369790093543438  accuracy:  0.867603550295858  time:  57.559483766555786\n",
      "epoch:  53  loss:  0.35005790245383095  accuracy:  0.8631656804733728  time:  57.36609673500061\n",
      "epoch:  54  loss:  0.35746967197346263  accuracy:  0.8616863905325444  time:  56.312766551971436\n",
      "epoch:  55  loss:  0.3353191815349742  accuracy:  0.8631656804733728  time:  57.05827212333679\n",
      "epoch:  56  loss:  0.29771203319018585  accuracy:  0.8831360946745562  time:  57.03820037841797\n",
      "epoch:  57  loss:  0.30750982834786705  accuracy:  0.8912721893491125  time:  57.10173273086548\n",
      "epoch:  58  loss:  0.291979614689329  accuracy:  0.8875739644970414  time:  56.98990201950073\n",
      "epoch:  59  loss:  0.2901578596490022  accuracy:  0.8868343195266272  time:  55.718116760253906\n",
      "epoch:  60  loss:  0.2772396095413935  accuracy:  0.8883136094674556  time:  55.75751519203186\n",
      "epoch:  61  loss:  0.2525899472271682  accuracy:  0.8979289940828402  time:  55.73118758201599\n",
      "epoch:  62  loss:  0.2508089993350186  accuracy:  0.9023668639053254  time:  55.80139970779419\n",
      "epoch:  63  loss:  0.25298925516190085  accuracy:  0.8994082840236687  time:  54.854016065597534\n",
      "epoch:  64  loss:  0.2272300999239638  accuracy:  0.9164201183431953  time:  55.03613877296448\n",
      "epoch:  65  loss:  0.24479078960235742  accuracy:  0.9112426035502958  time:  55.53664302825928\n",
      "epoch:  66  loss:  0.23110346127158174  accuracy:  0.9045857988165681  time:  55.616262912750244\n",
      "epoch:  67  loss:  0.21481990048347713  accuracy:  0.9215976331360947  time:  55.828678131103516\n",
      "epoch:  68  loss:  0.21277228096973966  accuracy:  0.9201183431952663  time:  55.818363904953\n",
      "epoch:  69  loss:  0.22220305629217854  accuracy:  0.9164201183431953  time:  56.17800259590149\n",
      "epoch:  70  loss:  0.20651499374656657  accuracy:  0.9201183431952663  time:  56.373926401138306\n",
      "epoch:  71  loss:  0.18335706037166116  accuracy:  0.9289940828402367  time:  57.038113594055176\n",
      "epoch:  72  loss:  0.19161746682276806  accuracy:  0.9282544378698225  time:  56.985617876052856\n",
      "epoch:  73  loss:  0.17771917607183374  accuracy:  0.9363905325443787  time:  59.63127565383911\n",
      "epoch:  74  loss:  0.18102142998477522  accuracy:  0.9260355029585798  time:  56.16291689872742\n",
      "epoch:  75  loss:  0.19008175990979612  accuracy:  0.9312130177514792  time:  56.72354006767273\n",
      "epoch:  76  loss:  0.1870751814929129  accuracy:  0.9252958579881657  time:  55.52703905105591\n",
      "epoch:  77  loss:  0.168779969351785  accuracy:  0.9297337278106509  time:  55.484758138656616\n",
      "epoch:  78  loss:  0.15829220070770925  accuracy:  0.9386094674556213  time:  55.934409856796265\n",
      "epoch:  79  loss:  0.14448849591715868  accuracy:  0.9497041420118343  time:  55.46300506591797\n",
      "epoch:  80  loss:  0.1528300607229787  accuracy:  0.9437869822485208  time:  54.949098348617554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  81  loss:  0.13876372657457267  accuracy:  0.9519230769230769  time:  54.83076572418213\n",
      "epoch:  82  loss:  0.1506129729129428  accuracy:  0.9452662721893491  time:  54.97597312927246\n",
      "epoch:  83  loss:  0.1529141421837611  accuracy:  0.9415680473372781  time:  54.89576840400696\n",
      "epoch:  84  loss:  0.13090036213608078  accuracy:  0.9489644970414202  time:  54.91924571990967\n",
      "epoch:  85  loss:  0.11827942274149904  accuracy:  0.9600591715976331  time:  54.802237033843994\n",
      "epoch:  86  loss:  0.12271266799976707  accuracy:  0.9578402366863905  time:  55.00700521469116\n",
      "epoch:  87  loss:  0.14324194378677285  accuracy:  0.9497041420118343  time:  54.79870295524597\n",
      "epoch:  88  loss:  0.14002300209445692  accuracy:  0.9482248520710059  time:  54.87346959114075\n",
      "epoch:  89  loss:  0.12753270610739179  accuracy:  0.9600591715976331  time:  54.7678120136261\n",
      "epoch:  90  loss:  0.10556780676303718  accuracy:  0.9622781065088757  time:  54.68027400970459\n",
      "epoch:  91  loss:  0.1261938282041659  accuracy:  0.9504437869822485  time:  54.430628061294556\n",
      "epoch:  92  loss:  0.1441247387480586  accuracy:  0.9497041420118343  time:  54.46588158607483\n",
      "epoch:  93  loss:  0.11561828901365774  accuracy:  0.9600591715976331  time:  54.518805503845215\n",
      "epoch:  94  loss:  0.12031969608885054  accuracy:  0.9556213017751479  time:  54.41961479187012\n",
      "epoch:  95  loss:  0.11399941384164099  accuracy:  0.959319526627219  time:  54.46174669265747\n",
      "epoch:  96  loss:  0.10985254176469388  accuracy:  0.9600591715976331  time:  54.39162755012512\n",
      "epoch:  97  loss:  0.09293114179313064  accuracy:  0.9696745562130178  time:  54.42824959754944\n",
      "epoch:  98  loss:  0.0930134531809017  accuracy:  0.9689349112426036  time:  54.305996894836426\n",
      "epoch:  99  loss:  0.0868119302699301  accuracy:  0.9659763313609467  time:  54.38186955451965\n",
      "epoch:  100  loss:  0.10206402405825138  accuracy:  0.9571005917159763  time:  54.49224615097046\n"
     ]
    }
   ],
   "source": [
    "current_image_dir = 'data/Frogger_Turk/Currrent_State'\n",
    "next_image_dir = 'data/Frogger_Turk/Next_State'\n",
    "loss_arr, acc_arr = train(current_image_dir, next_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAF3CAYAAACi+eJxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXZx/HvnWSSIYSEAAFC2BdZZDfiglvVKlgVbNWC\ntS6t0kVb7a7d9LXa2vZtrbVWpe51q7u8auu+W5Swb7JvCTskQMie3O8fM2AEkgySYTKT3+e65iJz\nlsmd4zG/PM95znPM3REREZHElRTrAkRERCS6FPYiIiIJTmEvIiKS4BT2IiIiCU5hLyIikuAU9iIi\nIglOYS8iIpLgFPYiIiIJTmEvIiKS4BT2IiIiCS4l1gU0p06dOnnv3r1jXYaIiMhhMXPmzK3untPU\ndgkV9r1796agoCDWZYiIiBwWZrYmku3UjS8iIpLgFPYiIiIJTmEvIiKS4BT2IiIiCU5hLyIikuAU\n9iIiIglOYS8iIpLgFPYiIiIJTmEvIiKS4BT2IiIiCU5hLyIikuAU9g3474ptLN6wM9ZliIiIHDKF\nfQN++OQc7n9/VazLEBEROWQK+wYEA8lU1NTFugwREZFDprBvQFpKEhXVtbEuQ0RE5JAp7BuQFkim\nUi17ERFJAAr7BgTVshcRkQShsG9AMJBMpcJeREQSgMK+AcFAEhXV6sYXEZH4p7BvQGg0vlr2IiIS\n/xT2DdBofBERSRRRC3sz62Fmb5nZYjNbaGbXHGAbM7O/mtlyM5tnZqPrrbvUzJaFX5dGq86GBDUa\nX0REEkRKFD+7BviRu88ys3bATDN7zd0X1dtmPDAg/DoGuAs4xsw6ADcA+YCH953m7sVRrPczgoFk\ntexFRCQhRK1l7+4b3H1W+OtdwGIgb5/NJgAPe8h0oL2Z5QJnAq+5+/ZwwL8GjItWrQcSuvWuDnc/\nnN9WRESk2R2Wa/Zm1hsYBXy0z6o8YF2994XhZQ0tP2zSAskA6soXEZG4F/WwN7MM4BngWnff9zFy\ndoBdvJHlB/r8KWZWYGYFW7ZsObRi60lLCR2aSt1+JyIicS6qYW9mAUJB/6i7P3uATQqBHvXedwfW\nN7J8P+4+1d3z3T0/JyeneQondM0eoFK334mISJyL5mh8A+4DFrv7nxvYbBpwSXhU/rHADnffALwC\nnGFm2WaWDZwRXnbY7Al7TawjIiLxLpqj8ccCXwfmm9mc8LKfAz0B3P1u4GXgLGA5UAZcHl633cx+\nA8wI73eTu2+PYq37CQZCfwdpYh0REYl3UQt7d3+fA197r7+NA1c1sO5+4P4olBaRYMqelr3CXkRE\n4ptm0GuAuvFFRCRRKOwbkLanG18texERiXMK+wbs6cbXffYiIhLvFPYNCKplLyIiCUJh34BPr9kr\n7EVEJL4p7Buw95q9uvFFRCTOKewbkLbnmr1a9iIiEucU9g3Yc81eA/RERCTeKewbkJqchJmu2YuI\nSPxT2DfAzAimJCvsRUQk7insGxEMJGkGPRERiXsK+0YEA2rZi4hI/FPYNyItJUkD9EREJO4p7Buh\nlr2IiCQChX0j0gLJmlRHRETinsK+EcGUJLXsRUQk7insGxEMJGsGPRERiXsK+0akpejWOxERiX8K\n+0YEA8lU1qhlLyIi8U1h3whNqiMiIolAYd+IYCCZCrXsRUQkzinsG6H77EVEJBEo7BsRDA/Qc/dY\nlyIiIvK5KewbkRZIBqCqVtftRUQkfinsG5GWEjo8GqQnIiLxTGHfiGC4Za+JdUREJJ4p7BuxJ+zV\nshcRkXimsG9EMBDuxtftdyIiEsdSovXBZnY/cDaw2d2HHmD9T4Cv1atjMJDj7tvNbDWwC6gFatw9\nP1p1NiYtZU83vlr2IiISv6LZsn8QGNfQSnf/o7uPdPeRwPXAO+6+vd4mXwivj0nQg1r2IiKSGKIW\n9u7+LrC9yQ1DJgOPR6uWz+vTa/YKexERiV8xv2ZvZumEegCeqbfYgVfNbKaZTYlNZRBM0QA9ERGJ\nf1G7Zn8QzgE+2KcLf6y7rzezzsBrZvZJuKdgP+E/BqYA9OzZs1kL29uNr5a9iIjEsZi37IFJ7NOF\n7+7rw/9uBp4DxjS0s7tPdfd8d8/Pyclp1sLUjS8iIokgpmFvZlnAycAL9Za1NbN2e74GzgAWxKK+\nPTPoVdaoG19EROJXNG+9exw4BehkZoXADUAAwN3vDm92HvCqu++ut2sX4Dkz21PfY+7+n2jV2Zg0\ntexFRCQBRC3s3X1yBNs8SOgWvfrLVgIjolPVwdlzzV4texERiWct4Zp9i5WanISZWvYiIhLfFPaN\nMDOCKckKexERiWsK+yYEA0nqxhcRkbimsG9Cmlr2IiIS5xT2TQgGkjSDnoiIxDWFfROCAbXsRUQk\nvinsm5AWSKZC1+xFRCSOKeybEExJUsteRETimsK+CWmBZI3GFxGRuKawb0IwJYlKtexFRCSOKeyb\noAF6IiIS7xT2TdCtdyIiEu8U9k0IBpKpqFHLXkRE4pfCvgnBQDKVatmLiEgcU9g3IS0liYqaWtw9\n1qWIiIh8Lgr7JgQDybhDVa1a9yIiEp8U9k1ISwkdIg3SExGReKWwb0IwkAyge+1FRCRuKeybsDfs\nNYueiIjEKYV9Ez7txlfLXkRE4pPCvgl7Wva6Zi8iIvFKYd+EYCDcstfEOiIiEqcU9k34tGWvsBcR\nkfiksG9CMEXd+CIiEt8U9k3Y041fqW58ERGJUwr7JqSpZS8iInFOYd+EvQP0dM1eRETilMK+CWka\noCciInEuamFvZveb2WYzW9DA+lPMbIeZzQm/fl1v3TgzW2Jmy83sumjVGIlPr9mrG19EROJTNFv2\nDwLjmtjmPXcfGX7dBGBmycCdwHhgCDDZzIZEsc5GpSYnYaa58UVEJH5FLezd/V1g++fYdQyw3N1X\nunsV8AQwoVmLOwhmFn6mvVr2IiISn2J9zf44M5trZv82syPDy/KAdfW2KQwvi5lgIFnX7EVEJG6l\nxPB7zwJ6uXupmZ0FPA8MAOwA23pDH2JmU4ApAD179oxGnQRTFPYiIhK/Ytayd/ed7l4a/vplIGBm\nnQi15HvU27Q7sL6Rz5nq7vnunp+TkxOVWoOBJN1nLyIicStmYW9mXc3Mwl+PCdeyDZgBDDCzPmaW\nCkwCpsWqTlA3voiIxLeodeOb2ePAKUAnMysEbgACAO5+N3A+8B0zqwHKgUnu7kCNmV0NvAIkA/e7\n+8Jo1RmJtECybr0TEZG4FbWwd/fJTaz/G/C3Bta9DLwcjbo+j7SUJLXsRUQkbsV6NH5cCAaSdeud\niIjELYV9BIIpSZpUR0RE4pbCPgIaoCciIvFMYR+BYCBJA/RERCRuKewjkKZJdUREJI4p7COgSXVE\nRCSeKewjEBqNX0toGgAREZH4orCPQDCQjDtU1ap1LyIi8UdhH4G0lNBh0iA9ERGJRwr7CAQDyQAa\npCciInFJYR+BvS17DdITEZE4pLCPgFr2IiISzxT2Efg07NWyFxGR+KOwj0AwEDpMFTVq2YuISPxR\n2EdgT8te1+xFRCQeKewjEEzRNXsREYlfCvsIpKkbX0RE4pjCPgKftuzVjS8iIvFHYR+BvQP01I0v\nIiJxSGEfgbQ9A/Q0Xa6IiMQhhX0E1LIXEZF4prCPQGpyEmZQqbAXEZE4pLCPgJmRlpJEhbrxRUQk\nDinsIxQMJKsbX0RE4pLCPkLBFIW9iIjEJ4V9hIKBJMqqFPYiIhJ/FPYR6puTwcvzN/CH/3xCpWbS\nExGROKKwj9Dtk0ZywVE9+PvbK5jwtw9YULQj1iWJiIhEJGphb2b3m9lmM1vQwPqvmdm88OtDMxtR\nb91qM5tvZnPMrCBaNR6MdsEAvz9/OPdfls/23VVMvPMDbn5xEau37o51aSIiIo0yd4/OB5udBJQC\nD7v70AOsPx5Y7O7FZjYeuNHdjwmvWw3ku/vWg/me+fn5XlAQ/b8NSsqq+M2Li3l+ThG1dc7Y/h2Z\nPKYnZwzpSmqKOktEROTwMLOZ7p7f5HbRCvtwEb2BFw8U9vtslw0scPe88PvVtOCw32PTzgqeKljH\n4x+vo6iknPbpAc4ensvEkXkc1SsbMztstYiISOsTadinHI5iIvBN4N/13jvwqpk5cI+7T41NWY3r\nkhnk6lMH8J1T+vPesi08O6uIp2cW8sj0tfTo0IYvDevGFwbmMLpXNoFktfhFRCQ2Yt6yN7MvAH8H\nTnD3beFl3dx9vZl1Bl4Dvufu7zaw/xRgCkDPnj2PWrNmTfP+EAeptLKGVxZs5Pk5Rfx3xTZq6px2\nwRROHNCJE/rnMLJHe47okkGKwl9ERA5RXHTjm9lw4DlgvLsvbWCbG4FSd//fpr7f4e7Gb8rOimo+\nWLaVt5ds4e2lm9m0sxII3bM/LC+L/N4dOHt4LkNyM9XlLyIiB63Fd+ObWU/gWeDr9YPezNoCSe6+\nK/z1GcBNMSrzkGQGA4wflsv4Ybm4O2u2lTG3sIS563Ywt7CEf7y7krveXsGAzhlMHJXHuSO60aND\neqzLFhGRBBPN0fiPA6cAnYBNwA1AAMDd7zaze4GvAHv63WvcPd/M+hJq7UPoj5HH3P2WSL5nS2vZ\nN6V4dxUvzd/AC3OKmLG6GDM4fXAXvnlCH47p00GtfRERaVSL6MY/3OIt7Otbt72Mf81Yx6MfraG4\nrJoju2UyYWQ3dpRXU1RczvqSCnZX1XDqoM5MGNmN/p3bxbpkERGJMYV9nKqoruW52UXc//4qlm0u\nJTnJ6JoZJC+7DQbMWL2dOofBuZlMHNmNSUf3JCs9EOuyRUQkBhT2cc7d2VJaSYf01M+M3N+8q4KX\n5m3ghTnrmbOuhLapyVx8XC+uOKEvOe3SYlixiIgcbgr7VmDxhp3c+dZyXpq/gdTkJCYd3YMfnTmQ\nzKBa+iIirUGkYa+bvePY4NxM/nbRaN744clMGNmNRz5ay8Q7P2DFltJYlyYiIi2Iwj4B9M3J4A/n\nj+DRK45hR1k1E//2AW8s3hTrskREpIVQ2CeQY/t2ZNr3TqBnx3SueLiAv76xjPKq2liXJSIiMaZr\n9gmovKqW65+dx/Nz1hNINkb2aM+xfTtyTJ+ODO+RpWv6IiIJQgP0Wjl3571lW/lg+Vamr9rOgqId\n1NaF/lv36dSWoXlZDM/L4rzReXTK0Ch+EZF4pLCXzyitrGHmmmLmF5Ywv2gH8wt3sH5HBe3TA9xw\nzhAmjszTjH0iInFGYS9NWrppFz97Zh6z15Zw6qDO3HLeUHKz2sS6LBERiZDCXiJSW+c8+OFq/vjK\nJwSSkjh9SBf65bSlX04G/Tpn0D8ng6QktfhFRFqiFv/UO2kZkpOMb57Qh9MHd+bWf3/CRyu38dzs\nor3rh+Zl8tvzhjG8e/sYVikiIociopa9mV0DPADsAu4FRgHXufur0S3v4Khl3zzKqmpYuWU3cwtL\n+Mvry9haWsklx/bS7HwiIi1Mc8+g9w1330no2fI5wOXArYdQn7Rg6akpDM3L4mvH9OKNH53MJcf2\n4uHpazjtT+/wVME6amrrYl2iiIgchEjDfs9F27OAB9x9br1lksAygwH+Z8JQXrhqLLlZQX7y9DxO\n+7NCX0QknkQa9jPN7FVCYf+KmbUD9Ju+FRnevT0vXDWWf1yST0ZaCj95eh6n/ukdHv1ojWbpExFp\n4SK9Zp8EjARWunuJmXUAurv7vGgXeDB0zf7wcHfeWLyZ299YxvyiHWS1CTBpTA++fmwvumenx7o8\nEZFWo1lvvTOzscAcd99tZhcDo4Hb3X3NoZfafBT2h5e7M2N1MQ9+uIpXFm7C3Zk8pic3nHMkqSl6\n7IKISLQ19613dwEjzGwE8FPgPuBh4OTPX6LEOzNjTJ8OjOnTgaKScv7x7koe/HA1q7bu5q6LjyKr\njUbui4i0BJE2v2o81AUwgVCL/nagXfTKkniT174NN557JH+6YAQzVm/n/Ls+ZN32sliXJSIiRB72\nu8zseuDrwEtmlgyo2Sb7+cpR3Xn4G8ewaWcF5/39Q+auK4l1SSIirV6kYf9VoJLQ/fYbgTzgj1Gr\nSuLacf068ux3j6dNahJfu/cjZq4pjnVJIiKtWkRhHw74R4EsMzsbqHD3h6NamcS1/p3b8dS3jien\nXRqX3v+xAl9EJIYiCnszuxD4GLgAuBD4yMzOj2ZhEv+6ZgV5/Mpj9wb+rLUKfBGRWIi0G/8XwNHu\nfqm7XwKMAX4VvbIkUewJ/E4ZqVx6nwJfRCQWIg37JHffXO/9toPYV1q5rllBHp9yLB0zUvnmgzPY\ntLMi1iWJiLQqkQb2f8zsFTO7zMwuA14CXo5eWZJocrPacN9lR1NRXccP/jWH2rqmJ3MSEZHmEekA\nvZ8AU4HhwAhgqrv/LJqFSeLpl5PBjecO4cMV27jn3RWxLkdEpNWIuCve3Z9x9x+6+w/c/blI9jGz\n+81ss5ktaGC9mdlfzWy5mc0zs9H11l1qZsvCr0sjrVNatgvze/ClYbn8+dWlzNb1exGRw6LRsDez\nXWa28wCvXWa2M4LPfxAY18j68cCA8GsKoWl5CT9o5wbgGEKDAW8ws+wIvp+0cGbGb788jC6ZQb7/\nxGx2VVTHuiQRkYTXaNi7ezt3zzzAq527Zzb14e7+LrC9kU0mAA97yHSgvZnlAmcCr7n7dncvBl6j\n8T8aJI5ktQlw+6SRFBWXc8MLC2NdjohIwov1iPo8YF2994XhZQ0tlwSR37sD3zq5H8/OLmLJxl2x\nLkdEJKHFOuztAMu8keX7f4DZFDMrMLOCLVu2NGtxEl1TTuxLemoyd729PNaliIgktFiHfSHQo977\n7sD6Rpbvx92nunu+u+fn5ORErVBpftltU7loTE/+b94GPSFPRCSKYh3204BLwqPyjwV2uPsG4BXg\nDDPLDg/MOyO8TBLMFSf2JcnQrXgiIlEU1bA3s8eB/wIDzazQzL5pZt82s2+HN3kZWAksB/4BfBfA\n3bcDvwFmhF83hZdJgumaFeQro7vzZEEhm3dpZj0RkWgw98SZySw/P98LCgpiXYYcpFVbd3Pan95m\nykn9uG78oFiXIyISN8xsprvnN7VdrLvxRejTqS3jh+XyyPQ17CjXffciIs1NYS8twndO7kdpZQ2P\nTF8T61JERBKOwl5ahKF5WZwyMIep765k+ebSWJcjIpJQFPbSYtx4zpEEkpO4+N6PdCueiEgzUthL\ni9G7U1seuWIM5dW1XHTvdDbu0Oh8EZHmoLCXFmVQ10we/sYYindX87V7p7OttDLWJYmIxD2FvbQ4\nI3q0575L8ykqKeeS+z+moro21iWJiMQ1hb20SMf07cidF41m4fqd/P4/n8S6HBGRuKawlxbrtMFd\nuOz43jzwwWreW6aHHImIfF4Ke2nRrhs/iP6dM/jxU3Mp3l0V63JEROKSwl5atGAgmb98dSTbd1fx\ni+fnk0jTO4uIHC4Ke2nxhuZl8aMzBvLy/I08O6so1uWIiMQdhb3EhStP7MuYPh24YdpCCos14Y6I\nyMFQ2EtcSE4y/nzhCNydnz49j7o6deeLiERKYS9xo3t2Or88ewgfrtjGox/pgTkiIpFS2EtcmXR0\nD046IoffvvwJa7epO19EJBIKe4krZsbvvzKMlGTjx0/PVXe+iEgEFPYSd3Kz2vDrs4fw8artPPjh\n6liXIyLS4insJS6df1R3ThvUmT+88gkrt5TGuhwRkRZNYS9xycz43ZeHkZaSzI+fmkutuvNFRBqk\nsJe41TkzyE0TjmTW2hL+8d7KWJcjItJiKewlrp07ohvjjuzKn19dytJNu2JdjohIi6Swl7hmZtx8\n3lAygin86Mm5VNfWxbokEZEWR2Evca9TRhq3TBzK/KId3PX2iliXIyLS4qTEugCR5jB+WC7njujG\nX99YRk1tHd86uR9t03R6i4iAWvaSQH4zcSjjh+Xy1zeXc/If3+bxj9dqlL6ICAp7SSBZbQLcMXkU\nz333eHp3TOf6Z+dz1u3vUVRSHuvSRERiSmEvCWdUz2ye+vZx3PW10RQWl3HN47Op0cA9EWnFFPaS\nkMyM8cNyufm8oRSsKeavby6PdUkiIjET1bA3s3FmtsTMlpvZdQdYf5uZzQm/lppZSb11tfXWTYtm\nnZK4zhvVnS+PzuNvby5j+sptsS5HRCQmohb2ZpYM3AmMB4YAk81sSP1t3P0H7j7S3UcCdwDP1ltd\nvmedu58brTol8f1mwlB6dWzLtU/MoXh3VazLERE57KLZsh8DLHf3le5eBTwBTGhk+8nA41GsR1qp\ntmkp3DF5FNt2V/KTp+fhrhH6ItK6RDPs84B19d4Xhpftx8x6AX2AN+stDppZgZlNN7OJDX0TM5sS\n3q5gy5YtzVG3JKCheVlcN34wry/exGMfr411OSIih1U0w94OsKyhJtUk4Gl3r623rKe75wMXAX8x\ns34H2tHdp7p7vrvn5+TkHFrFktC+MbY3J/TvxC0vLWbd9rJYlyMicthEM+wLgR713ncH1jew7ST2\n6cJ39/Xhf1cCbwOjmr9EaU3MjFu/MowkM3769DzqNOGOiLQS0Qz7GcAAM+tjZqmEAn2/UfVmNhDI\nBv5bb1m2maWFv+4EjAUWRbFWaSW6Z6fzyy8N5r8rt/HP6WtiXY6IyGERtbB39xrgauAVYDHwpLsv\nNLObzKz+6PrJwBP+2VFTg4ECM5sLvAXc6u4Ke2kWXz26BycfkcOt//6E1Vt3x7ocEZGos0QamZyf\nn+8FBQWxLkPiwIYd5Zxx27sM6tqOf005jqSkAw0xERFp2cxsZnh8W6M0g560SrlZbbjhnCOZsbqY\n215fGutyRESiSs8AlVbrK6Pz+HjVNu54czk9OqRzYX6PpncSEYlDCntptcyMW84bxvqSCn7+7Hzy\n2rdhbP9OsS5LRKTZqRtfWrVAchJ/v3g0/XIy+PY/Z7Jk465YlyQi0uw0QE8EKCopZ+KdH5CanMTE\nUd3YUV5NSVk1ZVW1TB7Tky8O6RLrEkVE9qMBeiIHIa99Gx647GjKq2u5+52VvDx/IwvX7+STDTuZ\n8s8C7n1vpebUF5G4pWv2ImFD87KY8YvTSbLQ9XyAiuparn1iDje/tJjC4nJ+dfYQknWbnojEGbXs\nRepJTrK9QQ8QDCTz96+N5soT+/Dgh6v51j8L2FVRHcMKRUQOnlr2Ik1ISjJ+8aUh9OiQzo3TFnLM\nb99g3NCunD+6O8f27agJeUSkxVPYi0TokuN6M6J7ex7/eC0vzdvAs7OKyGvfhl98aTBnDcuNdXki\nIg1S2IschBE92jOiR3tuPPdIXlm4kXvfW8X3H59Nu2AKJw7QI5ZFpGXSNXuRzyEYSGbCyDwevfIY\n+nfO4DuPzGLR+p2xLktE5IAU9iKHIDMY4IHLjyYjLYXLH/yYopLyWJckIrIfhb3IIcrNasOD3zia\nsspaLrv/Y3aUabS+iLQsCnuRZjCoayb3fP0oVm/bzcX3fcTmnRWxLklEZC+FvUgzOb5/J+6++ChW\nbCll4p0fsHiDruGLSMugsBdpRqcN7sKT3zqOOofz7/qQtz7ZHOuSREQU9iLNbWheFs9fNZbendry\nzYdm8OsXFvB/c9ezbnuZ5tcXkZjQU+9EoqSsqoafPzuffy/YSGVNHQAd26ZyQX4PfjZu4Gem5RUR\n+TwifeqdJtURiZL01BT+MmkUf6ytY8nGXcxZV8K7S7dw9zsrCCQbPzpjYKxLFJFWQmEvEmWB5CSG\n5mUxNC+Lrx3Tk+ufnc8dby6nc7s0vn5c71iXJyKtgMJe5DAyM26eOJStpVX8etpCOmakaV59EYk6\nDdATOcxSkpO4Y/IoRvfM5ton5vDhiq2xLklEEpzCXiQG2qQmc9+l+fTqmM7lD8zghTlFsS5JRBKY\nwl4kRtqnp/L4lGMZ0b091zwxh1v//Qm1dYlzd4yItBwKe5EY6pSRxiNXHMNFx/Tk7ndWcMVDM9hZ\nobn1RaR5aYCeSIylpiTx2/OGMSQ3kxunLWTsrW8yJDeTQV3bMSg3k6N6ZXNEl3axLlNE4pjCXqSF\nuPjYXgzOzeTpmYUs2biTp2cWsruqFoCx/TvyrZP6ceKATpqMR0QOWlTD3szGAbcDycC97n7rPusv\nA/4I7Bmd9Dd3vze87lLgl+HlN7v7Q9GsVaQlOKpXNkf1ygagrs4pLC7n3ws2cP8Hq7jk/o8ZnJvJ\nNaf1Z9xQ3a4nIpGL2nS5ZpYMLAW+CBQCM4DJ7r6o3jaXAfnufvU++3YACoB8wIGZwFHuXtzY99R0\nuZKoKmtqeWHOeqa+u5Llm0v515RjOaZvx1iXJSIxFul0udEcoDcGWO7uK929CngCmBDhvmcCr7n7\n9nDAvwaMi1KdIi1eWkoyF+b3YNrVY+me3Ybrn51PRXVtrMsSkTgRzbDPA9bVe18YXravr5jZPDN7\n2sx6HOS+Iq1KemoKvz1vGCu37ubOt5bHuhwRiRPRDPsDjSLa95rB/wG93X048Dqw57p8JPuGNjSb\nYmYFZlawZcuWz12sSLw46Ygcvjw6j7veXsEnG3fuXe7uPD+7iKsem8Uu3b4nIvVEM+wLgR713ncH\n1tffwN23uXtl+O0/gKMi3bfeZ0x193x3z8/JyWmWwkVaul99aQhZbQL87Jn51NY5W3ZV8q1/zuTa\nf83hpXkbuPudFbEuUURakGiG/QxggJn1MbNUYBIwrf4GZlZ/SPG5wOLw168AZ5hZtpllA2eEl4kI\nkN02lV+fM4S560r48VNzOeO2d3h76RZ+cdZgzhnRjXvfW8WGHeWxLlNEWoiohb271wBXEwrpxcCT\n7r7QzG4ys3PDm33fzBaa2Vzg+8Bl4X23A78h9AfDDOCm8DIRCTt3RDe+MDCH52YX0bNjW17+/olc\neVJffnrmQNzhT68ujXWJItJCRO3Wu1jQrXfS2hTvruL95VsZP7QrKcmf/u3+25cX84/3VvLS905k\nSLfMGFYoItHUEm69E5Eoy26byjkjun0m6AGuOqU/mcEAv/v34r3L3J1XF27kmidm8+5SDWYVaU00\nXa5IAspKD/C9U/tz80uLeWfpFrpmBrnpxYV8sHwbqSlJvDBnPeOHduWXZw8hr32bWJcrIlGmbnyR\nBFVZU8sVZDzdAAAWbUlEQVTpf36H3ZW1lJRV0S4Y4IdfPIIL8rvzwAeruePNZRjG907rz7dO6kdy\nkubcF4k36sYXaeXSUpL5xVlDKK2o4evH9uLtH5/Cpcf3Jj01hau+0J/XfnAyJw7oxB/+s4TbX9dg\nPpFEppa9SIKrrfNGW+0/fHIOz88u4slvHUd+7w6HsTIROVRq2YsIQJPd8/9z7pHkZbfhB0/O0cx7\nIglKYS/SyrULBrjtwpEUFZdz47RFTe8gInFHYS8i5PfuwNVf6M8zswp5ad6GWJcjIs1MYS8iAHzv\ntAGM6NGenz83n49WbiORxvOItHYKexEBIJCcxO1fHUkgOYmvTp3OhDs/4IU5RVTX1sW6NBE5RAp7\nEdmrd6e2vPfTL3DLeUMprazhmifmcNIf3uKNxZua3HdHeTWLN+zkrU82s3131WGoVkQipVvvROSA\n6uqcd5Zu4Y+vLGHxxp1cP34QV57YF7NPR/fPWVfC715ezKL1O9lVWbN3+Qn9O/HPb475zLYi0vwi\nvfVO0+WKyAElJRlfGNSZY/t25MdPzeW3L3/Csk2l3HLeMMqqavjDK0t4/OO15GSk8eXReeRlt6Fb\n+zYsWr+Tv7+9gneWbuGUgZ1j/WOICAp7EWlCm9Rk7pg8iv6dM7j9jWUs2bSLouJySsqr+cbYPlx7\n+gDaBQN7tz9jSFdenLeB3738CScOyNE0vCItgK7Zi0iTkpKMH3zxCP46eRRLNu6id6e2/N/VJ/Cr\ns4d8JugBUlOS+Om4gSzZtItnZhXGqGIRqU8texGJ2LkjunHqoM60TU1u9Hr8l4blcm+PVfzp1SWc\nM7wbbVKTP7O+eHcVH6zYyntLt/LBiq307JDObV8dSZfMYLR/BJFWSS17ETkoGWkpTQ68MzN+ftZg\nNu2s5L73VwLgHhrwN2nqfxl982tc/dhsXl6wgUFdM5mzroRz7nif2WuLD8ePINLqqGUvIlExpk8H\nvjikC3e/s5LcrDY8+OFq5hftIDcryDWnDeCkI3IYnpdFSnISn2zcyZUPF/DVe6Zzy3lDuSC/R6zL\nF0kouvVORKJmxZZSzrjtXWrrnN4d0/nOKf04b1R3UlP271Qs3l3FVY/N4sMV27jqC/34yZmDYlCx\nSHzRrXciEnP9cjK4Y/Io6twZPzS30ZH52W1TefgbY/jFcwu4860VDMtrz7ihXQ9jtSKJS2EvIlF1\n1rDciLdNSU7iNxOHsnjjTn72zDyGd8+iW/s2UaxOpHXQAD0RaVFSU5L466RR1NTWce0Tc6itS5xL\njSKxorAXkRand6e2/GbiUD5evZ2/vbl87/JdFdU8PbOQBz5YRVlVTSOfICL1qRtfRFqkL4/uznvL\ntnL7G0tpF0xh1tpiXl+8iYrq0FP47nlnJT8dN5CJI/NI0ix9Io3SaHwRabF2VVRz9h3vs2ZbGdnp\nAc4e3o2Jo7pR5/CbFxcxr3AHI7pn8b1TB5CX3YasNgHapwdoE2h80h+RRBHpaHyFvYi0aOu2l7Fi\nSynH9+v0mVv26uqc52YX8YdXPmHTzsrP7JOdHuCS43pz2fG9yW6berhLFjlsFPYi0iqUVdUwZ10J\nO8qq2VFeTUl5NQWrQ13+6anJTB7TkytP7EvXLE3FK4lH99mLSKuQnprC8f06fXbhybB00y7ufnsF\nD364mkemr+Gvk0dx5pG6b19ap6iOxjezcWa2xMyWm9l1B1j/QzNbZGbzzOwNM+tVb12tmc0Jv6ZF\ns04RSTxHdGnHn786krd/fAqDczP5ziMzeeyjtbEuSyQmohb2ZpYM3AmMB4YAk81syD6bzQby3X04\n8DTwh3rryt19ZPh1brTqFJHE1qNDOo9deQwnHZHDz5+bz+2vLyORLl+KRCKa3fhjgOXuvhLAzJ4A\nJgCL9mzg7m/V2346cHEU6xGRVio9NYV/XJLPdc/M57bXl7KuuIyTj8ghq02AzDYB2qYms6O8mu27\nq9i+u4rqOue8UXlkpOlKpySGaJ7JecC6eu8LgWMa2f6bwL/rvQ+aWQFQA9zq7s83f4ki0loEkpP4\n3wuG0zkzjbveXsHTMwsb3f7pmYU8dPnRtE/ffzT/uu1ldM5MIy0lOVrlijSraIb9gW5yPWDfmZld\nDOQDJ9db3NPd15tZX+BNM5vv7isOsO8UYApAz549D71qEUlYZsbPxg3imyf0oXh3FTvKq9lZUc3u\nyloy2wTokJ5Kh4xU5q0r4Zon5vDVe6bzzyvG0LldaCT/1tJKbpy2kBfnbSA3K8h3v9CfC/O7K/Sl\nxYvarXdmdhxwo7ufGX5/PYC7/26f7U4H7gBOdvfNDXzWg8CL7v50Y99Tt96JSHP5YPlWrny4gM7t\n0njkimOYvnI7N7+0iLLKWi4b25uZa4qZuaaYbntDv8cBH90rEk0xv8/ezFKApcBpQBEwA7jI3RfW\n22YUoYF549x9Wb3l2UCZu1eaWSfgv8AEd19EIxT2ItKcZq4p5vIHPqaypo7Kmjrye2Vz61eG0b9z\nO9yd95dv5bbXljJrbQl9c9ryP+ceyYkDcmJdtrQiMQ/7cBFnAX8BkoH73f0WM7sJKHD3aWb2OjAM\n2BDeZa27n2tmxwP3AHWE7hj4i7vf19T3U9iLSHNbtH4nv3phARNGduPiY3rtNw+/u/PmJ5u56cVF\nrNlWxvihXfnl2UPIO8CjeQuLy3hx3gZeWbiRXh3S+cm4QQfcTiRSLSLsDzeFvYjESkV1Lfe+t5K/\nvRV6St+oHtlktw3QPj2VdsEUZqzazqy1JQAMzctk2aZSAL51cj++fXJf0lM18l8OnsJeRCQGCovL\nuOON5azcWkpxWTXFu6soKa9mQOcMzhnRjXOGd6Nnx3QKi8u49d+f8OK8DXTNDPKbiUP54pAusS5f\n4ozCXkSkhXD3Bp/CV7B6O79+YSGLNuzkJ2cO5Lun9NMT+yRikYa9ho6KiERZY+Gd37sDz373eM4d\n0Y0/vrKEHz81j6qaur3r6+qcOetKWLR+Z8Tfr7bO2VpaSV1d4jTm5NDoIpGISIwFA8ncPmkkfTq1\n5fY3lrGuuIzLju/N20s28+YnW9haGnqE76mDOvOD049gWPes/T6jpraOj1dt56X5oQGAW0urSEky\numQGyc0KckTXdlx7+oC9cwZI66JufBGRFuSFOUX85Kl5VNXW0S4thZMH5nD64C6s31HO1HdXUlJW\nzReHdOGsYV3ZtLOS9SXlFBWXM7ewhK2lVbQJJHPq4M6M7pnNttJKNuyoYMOOcmatLSE9NZn/OfdI\nzh3RTZcKEoSu2YuIxKmVW0rZtLOSo3plf2ainl0V1TzwwWr+8d5KdlXUAJAZTCEvO50jumQw7siu\nnDKwM21S95/Rb/nmXfz4qXnMWVfCuCO7cvN5Q+mUkXbYfiaJDoW9iEiC2lVRzfqSCrq1D9IuGIh4\nv5raOu59fxV/fm0pwZQkvjy6Oxfm92BIt8woVivRpLAXEZEDWrZpF395YxmvLdxEVW0dw/KyuPDo\nHlxwVHeCAc3zH08U9iIi0qiSsiqen13EvwoKWbxhJznt0vjuKf2YPKbn3tAvq6rh/WVbmV+0g7OG\n5TI4d/9eAHdnbuEOCovL2L67im2lVeyqqOHLo/MYmrf/YEJpPgp7ERGJ2Ecrt3Hb60uZvnI7XTOD\nXHh0DxYW7eD95VuprHcr4JeG5/KD0wfQv3M7yqtqeW52EQ9+uIql4RkBAcwgkJSEGfz+K8OZOCrv\noOspq6phV0UNORlp+01R/HnsrKhm884K+ndud8if1ZIo7EVE5KB9uGIrf3ltGR+v3k737DZ8cUgX\nTh/chYFd2/HQh6u5//1VlFfXcsrAzsxaW0xJWTVHdsvk0uN7M6J7ezq0TSU7PUBJeTVXPTqLj1Zt\n54oT+nDd+EGkJEc2tctbSzbzw3/NobismkCykZvVhm7tg+T36sAlx/c66NsHX1m4kV8+v4Dtu6u4\n86LRjBva9fMcmhZJYS8iIp+Lu7NtdxUd26bud4vettJK7nl3JU/PLGRM7w5844Q+HN07+4C38lXX\n1nHzi4t46L9rGNu/I7ddOJLOmQ0HdU1tHX96bSl3vb2CQV3bMXlMTzbsqGB9STnrisuYs66EQFIS\n543K48qT+tK/c0ajP8e20kpumLaQF+dtYHBuJqnJxqINO/nHJfmcMrDz5zs4LYzCXkREWoQnZ6zj\nl88vAIOvjO7OlJP60qdT289sU1RSzrVPzGbG6mImj+nJDecM2W+w4Oqtu7n3/ZU8VVBIZU0dE0d2\n45bzhtE2bf/54f6zYAM/f24Buyqq+f6pA/j2Kf0oq6pl8tTprNhSyoOXj+G4fh2j+nMfDgp7ERFp\nMVZt3c3Ud1fyzKxCqmvrOHNIV7pkprFscynLN5eyeVcl6anJ/O7Lw5gwsvFr/NtKK7nv/VXc/c4K\nBnRux9RLjqJXx9AfD1U1dfz25cU8+OFqhuVl8acLR3BEl3af2XfS1OkUlZRz50WjMYOlm3axdFMp\n20orGZaXRX7vDozq2f6gbmuMFYW9iIi0OJt3VfDQh6v553/XUOfQr3MGAzpn0L9zBuOHdt0b2pF4\nb9kWrn5sNgB3TB5Fn05tufqxWcwt3MHlY3tz/fjBn5mUaG8NOyu48J7/snpb2d5lndulkZ2eyrLN\nu6hzSDI4oks7+nfOoG+ntvTNyWBg13YHvBshlhT2IiLSYtXWOUnW+EOCIrF2WxlT/lnA0k27aJua\nAgZ/PH8444bmNrrf5l0VvL1kC706pHNEl3Zkt00FoLSyhjlrSyhYs52560pYsWU3hcVl7Hmm0BlD\nunDjuUfSrX2bg651884KstumEohwoGIkFPYiItIqlFXV8IvnFlBUXM7/XjCCnh3Tm/XzK2tqWbut\njFcXbeKON5eRZMYPv3gElx3fO6I7DMqqapj67krueWclPxs3kMvG9mm22hT2IiIizWzd9jJ+/cIC\n3lqyhQGdM+jdqS2hGHWSzBjUtR2je2Uzqmc2GWkpPDOrkD+9uoRNOys5a1hXfjZu0EFdqmhKpGGv\nR9yKiIhEqEeHdO6/7Gj+s2AjU99bSWFxOXsuRFTV1vH64k3UeWhioY5tU9laWsXIHu2586LR5Pfu\nELO6FfYiIiIHwcwYPyyX8cP2HxdQWlnD3HUlzFxTzJKNuzhzaFfOGZ4b80cKK+xFRESaSUZaCmP7\nd2Js/06xLuUzmm9IoIiIiLRICnsREZEEp7AXERFJcAp7ERGRBKewFxERSXAKexERkQSnsBcREUlw\nUQ17MxtnZkvMbLmZXXeA9Wlm9q/w+o/MrHe9ddeHly8xszOjWaeIiEgii1rYm1kycCcwHhgCTDaz\nIfts9k2g2N37A7cBvw/vOwSYBBwJjAP+Hv48EREROUjRbNmPAZa7+0p3rwKeACbss80E4KHw108D\np1loTsEJwBPuXunuq4Dl4c8TERGRgxTNsM8D1tV7XxhedsBt3L0G2AF0jHBfERERiUA0w/5As/7v\n+zzdhraJZN/QB5hNMbMCMyvYsmXLQZYoIiKS+KIZ9oVAj3rvuwPrG9rGzFKALGB7hPsC4O5T3T3f\n3fNzcnKaqXQREZHEYe4HbDAf+geHwnspcBpQBMwALnL3hfW2uQoY5u7fNrNJwJfd/UIzOxJ4jNB1\n+m7AG8AAd69t4ntuAdY044/RCdjajJ/XGukYHjodw0OnY9g8dBwPXXMfw17u3mRLN2qPuHX3GjO7\nGngFSAbud/eFZnYTUODu04D7gH+a2XJCLfpJ4X0XmtmTwCKgBriqqaAP79esTXszK3D3/Ob8zNZG\nx/DQ6RgeOh3D5qHjeOhidQyj+jx7d38ZeHmfZb+u93UFcEED+94C3BLN+kRERFoDzaAnIiKS4BT2\njZsa6wISgI7hodMxPHQ6hs1Dx/HQxeQYRm2AnoiIiLQMatmLiIgkOIX9ATT1AB/Zn5n1MLO3zGyx\nmS00s2vCyzuY2Wtmtiz8b3asa23pzCzZzGab2Yvh933CD4paFn5wVGqsa2zpzKy9mT1tZp+Ez8nj\ndC4eHDP7Qfj/5QVm9riZBXUuNs7M7jezzWa2oN6yA553FvLXcM7MM7PR0axNYb+PCB/gI/urAX7k\n7oOBY4GrwsftOuANdx9AaL4E/fHUtGuAxfXe/x64LXwMiwk9QEoadzvwH3cfBIwgdDx1LkbIzPKA\n7wP57j6U0O3Tk9C52JQHCT28rb6GzrvxwIDwawpwVzQLU9jvL5IH+Mg+3H2Du88Kf72L0C/XPD77\nsKOHgImxqTA+mFl34EvAveH3BpxK6EFRoGPYJDPLBE4iNI8H7l7l7iXoXDxYKUCb8ARp6cAGdC42\nyt3fJTRnTH0NnXcTgIc9ZDrQ3sxyo1Wbwn5/egjPITKz3sAo4COgi7tvgNAfBEDn2FUWF/4C/BSo\nC7/vCJSEHxQFOh8j0RfYAjwQvhxyr5m1RedixNy9CPhfYC2hkN8BzETn4ufR0Hl3WLNGYb+/iB/C\nI/szswzgGeBad98Z63riiZmdDWx295n1Fx9gU52PjUsBRgN3ufsoYDfqsj8o4evKE4A+hKYsb0uo\n23lfOhc/v8P6/7bCfn8RP4RHPsvMAoSC/lF3fza8eNOerqnwv5tjVV8cGAuca2arCV0+OpVQS799\nuCsVdD5GohAodPePwu+fJhT+Ohcjdzqwyt23uHs18CxwPDoXP4+GzrvDmjUK+/3NAAaER52mEhqU\nMi3GNbV44WvL9wGL3f3P9VZNAy4Nf30p8MLhri1euPv17t7d3XsTOu/edPevAW8B54c30zFsgrtv\nBNaZ2cDwotMIPWdD52Lk1gLHmll6+P/tPcdQ5+LBa+i8mwZcEh6VfyywY093fzRoUp0DMLOzCLWo\n9jzAR3P0N8HMTgDeA+bz6fXmnxO6bv8k0JPQL5AL3H3fASyyDzM7Bfixu59tZn0JtfQ7ALOBi929\nMpb1tXRmNpLQIMdUYCVwOaHGjc7FCJnZ/wBfJXSnzWzgCkLXlHUuNsDMHgdOIfRku03ADcDzHOC8\nC/8R9TdCo/fLgMvdvSBqtSnsRUREEpu68UVERBKcwl5ERCTBKexFREQSnMJeREQkwSnsRUREEpzC\nXkSizsxO2fMUPxE5/BT2IiIiCU5hLyJ7mdnFZvaxmc0xs3vMLNnMSs3sT2Y2y8zeMLOc8LYjzWx6\n+Fncz9V7Tnd/M3vdzOaG9+kX/viMes+YfzQ8qYiIHAYKexEBwMwGE5oxbay7jwRqga8RegjKLHcf\nDbxDaFYwgIeBn7n7cEIzJ+5Z/ihwp7uPIDSf+p4pQEcB1wJDCD2ZbmzUfygRAUJPhxIRgdD850cB\nM8KN7jaEHtpRB/wrvM0jwLNmlgW0d/d3wssfAp4ys3ZAnrs/B+DuFQDhz/vY3QvD7+cAvYH3o/9j\niYjCXkT2MOAhd7/+MwvNfrXPdo3Nsd1Y13z9OdRr0e8fkcNG3fgisscbwPlm1hnAzDqYWS9Cvyf2\nPOnsIuB9d98BFJvZieHlXwfecfedQKGZTQx/RpqZpR/Wn0JE9qO/rEUEAHdfZGa/BF41sySgGrgK\n2A0caWYzgR2ErutD6HGdd4fDfM+T5SAU/PeY2U3hz7jgMP4YInIAeuqdiDTKzErdPSPWdYjI56du\nfBERkQSnlr2IiEiCU8teREQkwSnsRUREEpzCXkREJMEp7EVERBKcwl5ERCTBKexFREQS3P8DKw2f\nReeCNxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25f01d8a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(loss_arr)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(cur_image_dir, next_image_dir):\n",
    "    good_ids, training_indices, testing_indices, training_rationalizations, testing_rationalizations, trn_act, tst_act, vocab = load_data(\"Turk_Master_File.xlsx\", 'data/vocab_frogger.pkl')\n",
    "    cur_training_images, next_training_images, cur_test_images, next_test_images = load_images(current_image_dir, next_image_dir, good_ids, training_indices)\n",
    "    \n",
    "    rationalization_matrix, ration_sqn_len = create_rationalization_matrix(testing_rationalizations, vocab)\n",
    "    num_test = len(testing_rationalizations)\n",
    "    rationalization_matrix = np.array(rationalization_matrix)\n",
    "    ration_sqn_len = np.array(ration_sqn_len)\n",
    "    cur_test_images = np.array(cur_test_images)\n",
    "    tst_act = np.array(tst_act)\n",
    "    tf_accuracy, tf_image, tf_explanation, tf_explanation_sequence_length, tf_action, tf_prediction, tf_out_action = build_generator()\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    with tf.device('/cpu:0'):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, os.path.join(model_path, 'frogger_model-100'))\n",
    "\n",
    "\n",
    "        \n",
    "    tStart = time.time()\n",
    "    \n",
    "    sum_accuracy = 0\n",
    "    niter = 0\n",
    "    for current_batch_start_idx in range(0,num_test,batch_size):\n",
    "        if current_batch_start_idx + batch_size < num_test:\n",
    "            current_batch_file_idx = range(current_batch_start_idx,current_batch_start_idx+batch_size)\n",
    "        else:\n",
    "            current_batch_file_idx = range(current_batch_start_idx,num_test)\n",
    "\n",
    "            #print(current_batch_file_idx)\n",
    "\n",
    "        current_ration_text = rationalization_matrix[current_batch_file_idx,:]\n",
    "        current_sqn_len = ration_sqn_len[current_batch_file_idx]\n",
    "        current_img_list = cur_test_images[current_batch_file_idx]\n",
    "        current_actions = tst_act[current_batch_file_idx]\n",
    "        current_imgs_data = []\n",
    "        for img in current_img_list:\n",
    "            img_path = os.path.join(cur_image_dir, img)\n",
    "            img_arr = cv2.imread(img_path)\n",
    "            resized_img = cv2.resize(img_arr, (320,320))\n",
    "            current_imgs_data.append(resized_img)\n",
    "\n",
    "        current_imgs_data = np.array(current_imgs_data)\n",
    "            \n",
    "            \n",
    "        if len(current_ration_text) == batch_size:\n",
    "            accuracy, prediction, out_action = sess.run([tf_accuracy, tf_prediction, tf_out_action],\n",
    "                                            feed_dict={\n",
    "                                                tf_image: current_imgs_data,\n",
    "                                                tf_explanation: current_ration_text,\n",
    "                                                tf_explanation_sequence_length: current_sqn_len,\n",
    "                                                tf_action: current_actions})\n",
    "            print(\"original actions: \", current_actions)\n",
    "            print(\"prediction: \", prediction)\n",
    "            print(\"output action: \", out_action)\n",
    "            niter +=1\n",
    "            sum_accuracy += accuracy\n",
    "                \n",
    "        \n",
    "    avg_acc = sum_accuracy/ niter\n",
    "    print(\"accuracy: \", avg_acc, \" time: \", time.time() - tStart)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1:  Tensor(\"encoder/conv1/max_pooling2d/MaxPool:0\", shape=(1, 158, 158, 32), dtype=float32)\n",
      "conv2:  Tensor(\"encoder/conv2/max_pooling2d/MaxPool:0\", shape=(1, 77, 77, 64), dtype=float32)\n",
      "conv3:  Tensor(\"encoder/conv3/max_pooling2d/MaxPool:0\", shape=(1, 36, 36, 128), dtype=float32)\n",
      "conv4:  Tensor(\"encoder/conv4/max_pooling2d/MaxPool:0\", shape=(1, 17, 17, 128), dtype=float32)\n",
      "conv5:  Tensor(\"encoder/conv5/max_pooling2d/MaxPool:0\", shape=(1, 7, 7, 256), dtype=float32)\n",
      "flattened:  Tensor(\"encoder/flatten/Flatten/flatten/Reshape:0\", shape=(1, 12544), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from ./models_batch/frogger_model-100\n",
      "original actions:  [4]\n",
      "prediction:  [[7.0180516e-07 1.5096510e-04 1.0509549e-03 9.9878865e-01 8.6494883e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.5630120e-12 3.2461102e-08 4.8919581e-08 9.9999988e-01 9.9932743e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[3.2523161e-08 9.9753542e-03 2.9801445e-06 9.8976314e-01 2.5849926e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.3198085e-08 2.3176958e-06 5.3904946e-06 9.9500412e-01 4.9882326e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.5692688e-08 1.1532559e-08 3.0254593e-08 9.9999988e-01 8.0284819e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.4556059e-07 7.2206961e-07 6.4465261e-05 9.9993467e-01 5.6061289e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[8.06336855e-12 1.91897512e-10 2.10517754e-08 1.00000000e+00\n",
      "  1.01733434e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.6059649e-07 2.1837946e-04 3.2148368e-03 9.9656135e-01 5.2731912e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[8.7795815e-06 8.8350558e-01 7.1347929e-03 3.1366155e-02 7.7984646e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.7636218e-11 1.3744612e-07 8.2106089e-10 9.9999964e-01 1.9895852e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.4017137e-11 1.4200772e-05 6.5611556e-09 9.9998581e-01 1.6681573e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.8575053e-10 6.6949964e-05 3.1067757e-06 9.9992144e-01 8.4260009e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.19630190e-11 9.99639034e-01 2.08087547e-09 1.03295745e-08\n",
      "  3.60989361e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.1037703e-09 3.5434106e-05 7.1733026e-05 9.9989259e-01 2.6155416e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.7115305e-08 1.6719256e-02 1.2050342e-05 1.7305625e-03 9.8153818e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.8266616e-09 2.2249415e-03 3.3358285e-07 9.9776840e-01 6.2733566e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[5.3260821e-05 6.0474509e-01 2.0050302e-01 1.9400436e-01 6.9422257e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.8883280e-04 9.1156799e-01 1.8795140e-02 4.2602696e-02 2.6845338e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[0.00074655 0.5339097  0.00297458 0.00188552 0.4604837 ]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.7605355e-07 4.1917101e-01 5.3205658e-05 3.6926270e-08 5.8077538e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.1221057e-08 1.4320881e-05 1.5489475e-06 9.9989653e-01 8.7581160e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[7.9822321e-08 6.3614771e-02 1.3625764e-07 9.2694271e-01 9.4423573e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.2818301e-12 5.8588405e-08 7.7777507e-12 1.0000000e+00 7.7100670e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.7668139e-07 3.0291591e-05 5.3729462e-07 9.9961263e-01 3.5629657e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[5.6482037e-07 3.2767963e-02 9.4174230e-01 1.2364478e-03 2.4252675e-02]]\n",
      "output action:  [2]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.7063876e-09 1.0924914e-02 1.3464040e-06 1.5980321e-11 9.8907369e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6425831e-06 2.8071316e-02 3.3607348e-03 9.6848303e-01 8.3231185e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.1935846e-13 4.0040804e-11 9.0012336e-10 1.0000000e+00 3.1110247e-12]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[2.8228498e-14 9.3634673e-09 1.0597319e-11 8.0580376e-11 1.0000000e+00]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.8415511e-14 8.8644462e-08 4.6251173e-11 9.9999988e-01 3.8383744e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.7131835e-09 4.8855614e-05 2.5804334e-09 9.9749136e-01 2.4597736e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.5531138e-10 1.4196465e-07 2.1712372e-02 9.7828752e-01 5.7546203e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.9231823e-11 9.0055696e-09 4.4600118e-05 9.9989176e-01 6.3685846e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6403973e-08 1.1539133e-05 2.6090234e-07 9.9997032e-01 1.7922734e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.7794180e-15 2.0380496e-13 1.2630461e-11 1.0000000e+00 3.0804227e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.1866352e-11 1.1904717e-09 1.9531696e-07 9.9999964e-01 8.2678042e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.5835551e-10 8.2532479e-06 3.9039807e-07 9.9999130e-01 3.3624119e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.7231083e-11 5.3883650e-08 2.5952582e-07 9.9996185e-01 3.7788996e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[7.0436504e-12 1.0947951e-09 4.2743568e-07 9.9999952e-01 5.2321415e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.3169514e-07 6.7398747e-07 9.7555780e-01 2.4262059e-02 1.7925567e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.4623601e-08 2.3184075e-06 3.3467331e-03 9.9646938e-01 1.8152843e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.5302844e-07 3.1784960e-04 7.6202792e-03 9.9154526e-01 5.1615381e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4852204e-05 2.4012283e-03 6.7663813e-01 3.2083347e-01 9.2312031e-05]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.3974789e-05 6.1195665e-03 7.1558054e-03 9.8641217e-01 2.7839499e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.6989586e-05 9.7529715e-01 1.0701884e-02 1.1435751e-02 2.5281762e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.1451581e-05 9.5406878e-01 2.6286503e-05 4.5857478e-02 3.5890625e-05]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.3710886e-04 6.6814393e-01 1.0133775e-01 1.9852753e-01 3.1853680e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[6.3602918e-08 9.9333113e-01 8.5786519e-07 1.7194030e-03 4.9484791e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[8.1089559e-07 2.6688490e-03 3.5723567e-06 9.6617383e-01 3.1152956e-02]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[6.8753661e-09 9.9982029e-01 1.8695298e-06 1.7562961e-04 2.1274684e-06]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[6.9509336e-11 9.9999297e-01 3.5733626e-07 4.2327677e-08 6.6222847e-06]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.61399524e-08 9.87919688e-01 6.61147278e-05 4.26480756e-06\n",
      "  1.20099345e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.8282098e-11 9.9998939e-01 4.8569235e-11 3.0369616e-08 1.0584129e-05]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[8.0704114e-05 2.2481292e-02 2.9424607e-04 4.9584396e-02 9.2755944e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[6.4222564e-13 3.1104024e-09 1.3375399e-06 9.9999869e-01 2.6120475e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.2716866e-05 4.5551979e-03 1.9369651e-02 3.6092013e-05 9.7601640e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.2767538e-03 5.7192755e-01 5.8702622e-03 2.0958149e-04 4.2071590e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[8.3374651e-08 9.9975353e-01 3.4986790e-06 3.5192592e-08 2.4288923e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.1532142e-05 9.9515969e-01 7.4835607e-06 5.2538337e-05 4.7688033e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.6989185e-08 3.2464736e-06 1.3215139e-08 9.7783434e-01 2.2162436e-02]]\n",
      "output action:  [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original actions:  [4]\n",
      "prediction:  [[1.11459034e-04 5.25112271e-01 1.92792329e-03 1.90357622e-02\n",
      "  4.53812540e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.1439748e-05 4.5066305e-02 7.7118875e-06 3.8289762e-01 5.7201695e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.6909873e-05 8.7720293e-01 1.6619657e-04 2.4588260e-07 1.2261383e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.2641924e-07 7.9531066e-02 6.2234874e-05 3.1127911e-08 9.2040634e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.4264483e-08 2.8046373e-02 1.3424046e-06 1.4368395e-10 9.7195226e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.13928756e-07 9.28156316e-01 5.76475623e-09 2.14737993e-05\n",
      "  7.18221217e-02]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[9.7433847e-05 3.8315636e-01 8.0002574e-03 9.4905839e-04 6.0779691e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.4415415e-06 8.6009800e-02 6.2771072e-03 1.3062866e-04 9.0757799e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[7.4945831e-08 4.6692058e-01 2.2701040e-04 1.4589179e-07 5.3285217e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.7558592e-06 1.3363932e-02 5.3081731e-05 3.0967757e-02 9.5561343e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.3356614e-06 4.7612372e-01 5.2321440e-01 4.0127998e-06 6.5456674e-04]]\n",
      "output action:  [2]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.6093354e-05 3.1383891e-02 1.0035640e-02 3.3951599e-07 9.5856410e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.4408575e-06 3.1385891e-02 8.4545580e-04 9.6549124e-01 2.2689921e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.0904158e-04 1.0788970e-01 1.7717133e-03 1.0190169e-02 8.8003945e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.5099939e-07 2.0180358e-02 9.0097303e-05 2.3620864e-06 9.7972691e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.6603147e-08 8.6514949e-05 1.3464541e-04 2.3087102e-07 9.9977857e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.1815861e-03 1.0764822e-02 3.6715304e-03 2.5251884e-06 9.8437959e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.4777549e-11 4.2929515e-10 9.0152874e-10 9.9999988e-01 6.9861215e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.9303291e-10 2.1632498e-08 1.5998695e-07 9.9999976e-01 4.0357881e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.5026873e-12 1.4721707e-07 1.3022413e-09 9.9999988e-01 6.0141192e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[3.2832295e-09 1.9614030e-02 9.8038596e-01 1.6068529e-09 3.6999442e-08]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[2.5702445e-08 5.6130370e-06 9.9997818e-01 1.1784402e-05 4.4499470e-06]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[6.1536963e-11 8.9295380e-09 1.0000000e+00 3.0917228e-12 6.4675394e-09]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[6.8786546e-11 8.1455354e-10 1.0000000e+00 3.4425516e-09 8.1390750e-10]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.8923423e-09 4.5095004e-07 4.1442920e-05 9.9994528e-01 1.2897543e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.4401792e-06 4.7283919e-04 9.2138080e-03 9.8911881e-01 1.1929894e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.3265931e-07 1.5555176e-02 3.9998267e-05 9.8157078e-01 2.8335825e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.2938527e-11 6.9931622e-05 8.5640300e-10 9.9993002e-01 5.7259819e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.6371121e-11 4.4190765e-06 2.0340316e-09 9.9999475e-01 8.7224987e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.0008314e-07 1.8000148e-02 2.1299463e-06 1.1229923e-05 9.8198640e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.3740689e-05 4.8041591e-01 1.2451714e-03 5.1810008e-01 2.0504762e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [0]\n",
      "prediction:  [[0.5893179  0.01669521 0.00429807 0.36856255 0.02112616]]\n",
      "output action:  [0]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.8430367e-04 5.9992233e-03 8.5734606e-02 9.0600091e-01 2.0810245e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.1269819e-04 3.5065413e-01 3.1738269e-01 6.3697218e-05 3.3168679e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[8.2542583e-06 5.0120628e-01 2.7312227e-03 3.3120145e-04 4.9572313e-01]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.90162998e-13 1.06893815e-07 2.18661338e-08 9.99999881e-01\n",
      "  3.15459936e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4278580e-11 3.6642345e-09 6.7938752e-11 1.0000000e+00 8.2115315e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.9309387e-12 1.2683972e-09 5.5926456e-08 1.0000000e+00 2.8685811e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[3.8658476e-11 1.5029759e-06 8.8342783e-10 1.0210740e-08 9.9999845e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.7285422e-12 2.1001263e-08 8.9459718e-07 9.9999905e-01 5.5389453e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4474867e-10 1.6022787e-07 5.4694972e-08 9.9772769e-01 2.2721183e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[9.6070485e-10 2.8627434e-07 5.1025822e-06 9.9998999e-01 4.6452897e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [2]\n",
      "prediction:  [[1.3205343e-07 1.6177204e-04 9.9981695e-01 7.1251307e-09 2.1175965e-05]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[4.690059e-10 8.424119e-09 1.000000e+00 6.443105e-11 5.388794e-09]]\n",
      "output action:  [2]\n",
      "original actions:  [2]\n",
      "prediction:  [[6.0841789e-09 1.3839387e-08 9.9999988e-01 1.4305377e-09 7.9730917e-08]]\n",
      "output action:  [2]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.1302184e-09 1.1709277e-08 9.7681650e-06 9.9999022e-01 5.7229883e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.776618e-10 9.781389e-11 2.984729e-09 1.000000e+00 9.267310e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4510393e-08 1.7434033e-04 4.5868966e-09 9.9982423e-01 1.4234671e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[5.0257197e-05 2.5962712e-03 9.8758322e-01 3.3986121e-03 6.3716234e-03]]\n",
      "output action:  [2]\n",
      "original actions:  [1]\n",
      "prediction:  [[9.4682955e-06 3.7375123e-03 2.0638251e-01 7.8892654e-01 9.4394089e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.0578390e-06 1.0287719e-05 3.4006166e-07 9.9965811e-01 3.2818684e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[7.6982198e-10 1.4036230e-07 4.0395229e-05 9.9995947e-01 2.6934694e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.7324563e-13 2.4242741e-08 3.3086747e-09 1.0000000e+00 1.0897238e-11]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.5394023e-12 7.9256006e-09 3.0425293e-09 1.0000000e+00 1.2236022e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.1923336e-09 1.4261032e-07 2.8357421e-05 9.9971610e-01 2.5543181e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.42887818e-11 1.48265766e-09 2.09964268e-09 1.00000000e+00\n",
      "  1.28855655e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.1495403e-07 4.8572583e-06 1.6141197e-04 9.9983358e-01 1.0550761e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[6.9690642e-10 3.0828069e-08 1.2197250e-07 9.9999964e-01 1.7897978e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[5.4258137e-05 1.3128654e-03 6.0615400e-03 9.9115843e-01 1.4128775e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.6911492e-05 2.5477722e-02 1.4665772e-04 9.7354060e-01 8.0807734e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.3810933e-05 4.3741584e-02 1.0542520e-04 9.5396376e-01 2.1653860e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.1806092e-09 8.2314844e-05 1.9384920e-06 9.9991572e-01 3.2888369e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[5.6682796e-09 1.3098216e-03 8.8072801e-07 9.9868888e-01 5.3488947e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.4365156e-13 1.9170341e-09 5.0124033e-12 9.9999833e-01 1.6623674e-06]]\n",
      "output action:  [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original actions:  [3]\n",
      "prediction:  [[9.9806936e-13 2.4194928e-12 8.9469473e-12 1.0000000e+00 3.8815118e-10]]\n",
      "output action:  [3]\n",
      "original actions:  [0]\n",
      "prediction:  [[4.6912299e-07 1.3429556e-05 4.9949437e-04 9.9948251e-01 4.0563359e-06]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.6372296e-08 2.6544969e-06 1.5456603e-06 9.9999511e-01 7.3593168e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4841651e-07 9.3064709e-06 3.0309893e-05 9.9804890e-01 1.9111627e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.0701351e-18 3.8747228e-13 1.2239855e-11 1.0000000e+00 9.6111844e-16]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[4.3552750e-19 6.2124405e-14 7.8436952e-14 1.0000000e+00 2.8093786e-14]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[2.1163563e-05 3.3592532e-04 6.9463238e-02 8.4959322e-07 9.3017888e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.3060437e-08 6.2292202e-07 3.3686232e-05 9.9857867e-01 1.3870907e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[1.4224817e-04 6.9446065e-03 9.3328141e-05 1.5504365e-05 9.9280435e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [0]\n",
      "prediction:  [[2.9835717e-06 9.9931717e-01 2.5756358e-07 5.2393688e-04 1.5570404e-04]]\n",
      "output action:  [1]\n",
      "original actions:  [4]\n",
      "prediction:  [[8.6362261e-06 1.5638563e-01 4.2193837e-04 8.3324754e-01 9.9362219e-03]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[3.6685640e-04 5.2861313e-05 2.1809172e-04 9.9876249e-01 5.9969816e-04]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.4641495e-06 5.7156461e-01 4.5467327e-06 4.2274693e-01 5.6814188e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.4766368e-06 9.9320215e-01 7.1154108e-07 3.0118234e-03 3.7838712e-03]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[4.8414250e-09 5.2859814e-06 3.7631072e-08 9.9990880e-01 8.5830929e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.5548603e-05 9.9949956e-01 2.9713401e-04 1.6612482e-04 2.1676216e-05]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.2973256e-11 3.4291882e-06 3.1341176e-07 9.9999630e-01 1.4857209e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.7652555e-09 2.4063817e-07 6.2463892e-09 9.9999976e-01 7.6018365e-09]]\n",
      "output action:  [3]\n",
      "original actions:  [4]\n",
      "prediction:  [[4.8321791e-09 2.4736395e-05 5.7950102e-09 2.1540194e-08 9.9997520e-01]]\n",
      "output action:  [4]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.3891209e-11 1.2910039e-06 5.3172122e-10 9.9999857e-01 8.9817476e-08]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[3.4925343e-08 1.8064042e-06 3.7855659e-07 7.9218417e-01 2.0781350e-01]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[2.4596899e-08 2.2501848e-03 4.9493229e-07 9.9773633e-01 1.3018935e-05]]\n",
      "output action:  [3]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.2520839e-12 9.9999344e-01 6.5881773e-06 1.5577342e-12 4.0499977e-09]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[2.4880990e-13 9.9999988e-01 3.1413101e-11 8.0154904e-13 6.4910104e-08]]\n",
      "output action:  [1]\n",
      "original actions:  [1]\n",
      "prediction:  [[1.3146989e-09 9.9999547e-01 1.4490278e-11 3.1562394e-07 4.1996191e-06]]\n",
      "output action:  [1]\n",
      "original actions:  [3]\n",
      "prediction:  [[1.1445195e-13 7.9176637e-08 2.2761781e-14 9.9999893e-01 9.6294207e-07]]\n",
      "output action:  [3]\n",
      "original actions:  [3]\n",
      "prediction:  [[8.5958568e-10 1.2752803e-06 4.8952433e-09 9.9999833e-01 3.5005317e-07]]\n",
      "output action:  [3]\n",
      "accuracy:  0.7417218543046358  time:  10.831035375595093\n"
     ]
    }
   ],
   "source": [
    "current_image_dir = 'data/Frogger_Turk/Currrent_State'\n",
    "next_image_dir = 'data/Frogger_Turk/Next_State'\n",
    "test(current_image_dir, next_image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plot the training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = [0,10,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = [0.447, 0.503, 0.528, 0.58, 0.726, 0.818, 0.876, 0.918, 0.936, 0.967, 0.972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = [0.483, 0.503, 0.523, 0.642, 0.775, 0.907, 0.953, 0.954, 0.967, 0.974, 0.973]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAF3CAYAAAC8MNLCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e3f824dba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epoch, training, label='training')\n",
    "plt.plot(epoch, testing, label='testing')\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/vocab_frogger.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<build_vocab.Vocabulary at 0x21fbfcd0320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_loss, tf_acc, tf_image, tf_explanation, tf_explanation_sequence_length, tf_action, tf_pred = build_model()\n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
    "    tf.global_variables_initializer().run()\n",
    "    loss_arr = []\n",
    "    acc_arr = []\n",
    "    image_ids_list = image_to_char_list.keys()\n",
    "    image_ids_list = np.array(list(image_ids_list))\n",
    "    #print(type(image_ids_list))\n",
    "    for epoch in range(0, max_epoch):\n",
    "        image_ids_list = shuffle(image_ids_list)\n",
    "\n",
    "        #print(np.any(np.isnan(trn_act)))\n",
    "        tStart = time.time()\n",
    "        niter = 0\n",
    "        sum_loss = 0\n",
    "        sum_accuracy = 0\n",
    "        num_train = len(image_ids_list)\n",
    "        for current_batch_start_idx in range(0,num_train,batch_size):\n",
    "            if current_batch_start_idx + batch_size < num_train:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,current_batch_start_idx+batch_size)\n",
    "            else:\n",
    "                current_batch_file_idx = range(current_batch_start_idx,num_train)\n",
    "\n",
    "            current_img_list = image_ids_list[current_batch_file_idx]\n",
    "            \n",
    "            current_imgs_data = []\n",
    "            sentence_list = []\n",
    "            action_list = []\n",
    "            try:\n",
    "                for img_path in current_img_list:\n",
    "                    #img_path = os.path.join(cur_image_dir, img)\n",
    "                    img_arr = cv2.imread(img_path)\n",
    "                    resized_img = cv2.resize(img_arr, (224,224))\n",
    "                    x = np.expand_dims(resized_img, axis=0)\n",
    "                    image_feature = model.predict(x)\n",
    "                    current_imgs_data.append(image_feature)\n",
    "                    sentence = image_to_sent_list[img_path]\n",
    "                    action = image_to_char_list[img_path]\n",
    "                    sentence_list.append(sentence)\n",
    "                    action_list.append(action)\n",
    "\n",
    "\n",
    "                current_imgs_data = np.array(current_imgs_data)\n",
    "                current_imgs_data = np.reshape(current_imgs_data,(batch_size, -1))\n",
    "                sentence_matrix, sequence_length_arr = create_rationalization_matrix(sentence_list)\n",
    "                sentence_matrix = np.array(sentence_matrix)\n",
    "                sentence_matrix = np.reshape(sentence_matrix,(batch_size, -1))\n",
    "                sequence_length_arr = np.array(sequence_length_arr)\n",
    "                sequence_length_arr = np.reshape(sequence_length_arr, (batch_size))\n",
    "                action_arr = np.array(action_list)\n",
    "\n",
    "\n",
    "\n",
    "                if len(action_arr) == batch_size:\n",
    "                    _, loss, accuracy, prediction = sess.run([train_op, tf_loss, tf_acc, tf_pred],\n",
    "                        feed_dict={\n",
    "                            tf_image: current_imgs_data,\n",
    "                            tf_explanation: sentence_matrix,\n",
    "                            tf_explanation_sequence_length: sequence_length_arr,\n",
    "                            tf_action: action_arr})\n",
    "                    niter +=1\n",
    "                    sum_loss += loss\n",
    "                    sum_accuracy += accuracy\n",
    "                    #print(\"iter: \", niter, \" loss: \", loss, \" accuracy: \", accuracy)\n",
    "                    #print(\"current_actions\", current_actions)\n",
    "                    #print(\"prediction\", prediction)\n",
    "            except Exception as e:\n",
    "                #pass\n",
    "                print(\"exception: \", current_img_list)\n",
    "                \n",
    "                \n",
    "        \n",
    "        avg_loss = sum_loss / niter\n",
    "        avg_acc = sum_accuracy/ niter\n",
    "        print(\"epoch: \", epoch, \" loss: \", avg_loss, \" accuracy: \", avg_acc, \" time: \", time.time() - tStart)\n",
    "        f_acc= open(\"train_acc.txt\",\"a+\")\n",
    "        f_acc.write(\"epoch: \"+ str(epoch) + \" \"+\"Accuracy is: \" + str(avg_acc)+ \"%\\n\")\n",
    "        f_acc.close()\n",
    "        \n",
    "        loss_arr.append(avg_loss)\n",
    "        acc_arr.append(avg_acc)\n",
    "        \n",
    "        if np.mod(epoch, 10) == 0:\n",
    "            print (\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "            saver.save(sess, os.path.join(model_path, 'frogger_model'), global_step=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
